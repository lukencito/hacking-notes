[["index.html", "Hacking Notes 1 Whoami", " Hacking Notes notluken 2024-10-30 1 Whoami "],["pentest-overview.html", "2 Pentest Overview 2.1 Penetration Testing Overview 2.2 Laws and Regulations 2.3 Pre-Engagement 2.4 Information Gathering 2.5 Vulnerability Assessment 2.6 Explotation 2.7 Post-Explotation 2.8 Lateral Movement 2.9 Proof-of-Concept 2.10 Post-Engagement", " 2 Pentest Overview 2.1 Penetration Testing Overview IT is an integral part of nearly every company. The amount of critical and confidential data stored in IT systems is constantly growing, as is dependence on the uninterrupted functioning of the IT systems in use. Therefore, attacks against corporate networks, disruption of system availability, and other ways of causing significant damage to a company (such as ransomware attacks) are becoming increasingly common. Important company information obtained through security breaches and cyber-attacks may be sold to competitors, leaked on public forums, or used for other nefarious purposes. System failures are deliberately triggered because they are increasingly difficult to counteract. A Penetration Test (Pentest) is an organized, targeted, and authorized attack attempt to test IT infrastructure and its defenders to determine their susceptibility to IT security vulnerabilities. A pentest uses methods and techniques that real attackers use. As penetration testers, we apply various techniques and analyses to gauge the impact that a particular vulnerability or chain of vulnerabilities may have on the confidentiality, integrity, and availability of an organization’s IT systems and data. A pentest aims to uncover and identify ALL vulnerabilities in the systems under investigation and improve the security for the tested systems. Other assessments, such as a red team assessment, may be scenario-based and focus on only the vulnerabilities leveraged to reach a specific end goal (i.e., accessing the CEO’s email inbox or obtaining a flag planted on a critical server). 2.1.1 Risk Management In general, it is also a part of risk management for a company. The main goal of IT security risk management is to identify, evaluate, and mitigate any potential risks that could damage the confidentiality, integrity, and availability of an organization’s information systems and data and reduce the overall risk to an acceptable level. This includes identifying potential threats, evaluating their risks, and taking the necessary steps to reduce or eliminate them. This is done by implementing the appropriate security controls and policies, including access control, encryption, and other security measures. By taking the time to properly manage the security risks of an organization’s IT systems, it is possible to ensure that the data is kept safe and secure. However, we cannot eliminate every risk. There’s still the nature of the inherent risk of a security breach that is present even when the organization has taken all reasonable steps to manage the risk. Therefore, some risks will remain. Inherent risk is the level of risk that is present even when the appropriate security controls are in place. Companies can accept, transfer, avoid and mitigate risks in various ways. For example, they can purchase insurance to cover certain risks, such as natural disasters or accidents. By entering into a contract, they can also transfer their risks to another party, such as a third-party service provider. Additionally, they can implement preventive measures to reduce the likelihood of certain risks occurring, and if certain risks do occur, they can put in place processes to minimize their impact. Finally, they can use financial instruments, such as derivatives, to reduce the economic consequences of specific risks. All of these strategies can help companies effectively manage their risks. During a pentest, we prepare detailed documentation on the steps taken and the results achieved. However, it is the client’s responsibility or the operator of their systems under investigation to rectify the vulnerabilities found. Our role is as trusted advisors to report vulnerabilities, detailed reproduction steps, and provide appropriate remediation recommendations, but we do not go in and apply patches or make code changes, etc. It is important to note that a pentest is not monitoring the IT infrastructure or systems but a momentary snapshot of the security status. A statement to this regard should be reflected in our penetration test report deliverable. 2.1.2 Vulnerability Assessments Vulnerability analysis is a generic term that can include vulnerability or security assessments and penetration tests. In contrast to a penetration test, vulnerability or security assessments are performed using purely automated tools. Systems are checked against known issues and security vulnerabilities by running scanning tools like Nessus, Qualys, OpenVAS, and similar. In most cases, these automated checks cannot adapt the attacks to the configurations of the target system. This is why manual testing conducted by an experienced human tester is essential. On the other hand, a pentest is a mix of automated and manual testing/validation and is performed after extensive, in most cases, manual information gathering. It is individually tailored and adjusted to the system being tested. Planning, execution, and selection of the tools used are much more complex in a pentest. Both penetration tests and other security assessments may only be carried out after mutual agreement between the contracting company and the organization that employs the penetration tester. This is because individual tests and activities performed during the pentest could be treated as criminal offenses if the tester does not have explicit written authorization to attack the customer’s systems. The organization commissioning the penetration test may only request testing against its’ own assets. If they are using any third parties to host websites or other infrastructure, they need to gain explicit written approval from these entities in most cases. Companies like Amazon no longer require prior authorization for testing certain services per this policy, if a company is using AWS to host some or all of their infrastructure. This varies from provider to provider, so it is always best to confirm asset ownership with the client during the scoping phase and check to see if any third parties they use require a written request process before any testing is performed. A successful pentest requires a considerable amount of organization and preparation. There must be a straightforward process model that we can follow and, at the same time, adapt to the needs of our clients, as every environment we encounter will be different and have its own nuances. In some cases, we may work with clients who have never experienced a pentest before, and we have to be able to explain this process in detail to make sure they have a clear understanding of our planned activities, and we help them scope the assessment accurately. In principle, employees are not informed about the upcoming penetration tests. However, managers may decide to inform their employees about the tests. This is because employees have a right to know when they have no expectation of privacy. Because we, as penetration testers, can find personal data, such as names, addresses, salaries, and much more. The best thing we can do to uphold the Data Protection Act is to keep this information private. Another example would be that we get access to a database with credit card numbers, names, and CVV codes. Accordingly, we recommend that our customers improve and change the passwords as soon as possible and encrypt the data on the database. 2.1.3 Testing Methods An essential part of the process is the starting point from which we should perform our pentest. Each pentest can be performed from two different perspectives: External or Internal 2.1.3.1 External Penetration Test Many pentests are performed from an external perspective or as an anonymous user on the Internet. Most customers want to ensure that they are as protected as possible against attacks on their external network perimeter. We can perform testing from our own host (hopefully using a VPN connection to avoid our ISP blocking us) or from a VPS. Some clients will not care about stealth, while others will request that we proceed as quietly as possible and approach the target systems to avoid being banned by the firewalls and IDS/IPS systems and avoid triggering an alarm. They may ask for a stealthy or “hybrid” approach where we gradually become “noisier” to test their detection capabilities. Ultimately our goal here is to access external-facing hosts, obtain sensitive data, or gain access to the internal network. 2.1.3.2 Internal Penetration Test In contrast to an external pentest, an internal pentest is when we perform testing from within the corporate network. This stage may be executed after successfully penetrating the corporate network via the external pentest or starting from an assumed breach scenario. Internal pentests may also access isolated systems with no internet access whatsoever, which usually requires our physical presence at the client’s facility. 2.1.4 Types of Penetration Testing No matter how we begin the pentest, the type of pentest plays an important role. This type determines how much information is made available to us. We can narrow down these types to the following: Type Information Provided Blackbox Minimal. Only the essential information, such as IP addresses and domains, is provided. Greybox Extended. In this case, we are provided with additional information, such as specific URLs, hostnames, subnets, and similar. Whitebox Maximum. Here everything is disclosed to us. This gives us an internal view of the entire structure, which allows us to prepare an attack using internal information. We may be given detailed configurations, admin credentials, web application source code, etc. Red-Teaming May include physical testing and social engineering, among other things. Can be combined with any of the above types. Purple-Teaming It can be combined with any of the above types. However, it focuses on working closely with the defenders. The less information we are provided with, the longer and more complex the approach will take. For example, for a blackbox penetration test, we must first get an overview of which servers, hosts, and services are present in the infrastructure, especially if entire networks are tested. This type of recon can take a considerable amount of time, especially if the client has requested a more stealthy approach to testing. 2.1.5 Types of Testing Environments Apart from the test method and the type of test, another consideration is what is to be tested, which can be summarized in the following categories: Network Web App Mobile API Thick Clients IoT Cloud Source Code Physical Security Employees Hosts Server Security Policies Firewalls IDS/IPS It is important to note that these categories can often be mixed. All listed test components may be included depending on the type of test to be performed. Now we’ll shift gears and cover the Penetration Process in-depth to see how each phase is broken down and depends on the previous one. 2.2 Laws and Regulations Each country has specific federal laws which regulate computer-related activities, copyright protection, interception of electronic communications, use and disclosure of protected health information, and collection of personal information from children, respectively. It is essential to follow these laws to protect individuals from unauthorized access and exploitation of their data and to ensure their privacy. We must be aware of these laws to ensure our research activities are compliant and do not violate any of the provisions of the law. Failure to comply with these laws can result in civil or criminal penalties, making it essential for individuals to familiarize themselves with the law and understand the potential implications of their activities. Furthermore, it is crucial to ensure that research activities adhere to these laws’ requirements to protect individuals’ privacy and guard against the potential misuse of their data. By following these laws and exercising caution when conducting research activities, security researchers can help ensure that individuals’ data is kept secure and their rights are protected. Here is a summary of the related laws and regulations for a few countries and regions: Categories USA Europe UK India China Protecting critical information infrastructure and personal data Cybersecurity Information Sharing Act (CISA) General Data Protection Regulation (GDPR) Data Protection Act 2018 Information Technology Act 2000 Cyber Security Law Criminalizing malicious computer usage and unauthorized access to computer systems Computer Fraud and Abuse Act (CFAA) Network and Information Systems Directive (NISD) Computer Misuse Act 1990 Information Technology Act 2000 National Security Law Prohibiting circumventing technological measures to protect copyrighted works Digital Millennium Copyright Act (DMCA) Cybercrime Convention of the Council of Europe Anti-Terrorism Law Regulating the interception of electronic communications Electronic Communications Privacy Act (ECPA) E-Privacy Directive 2002/58/EC Human Rights Act 1998 (HRA) Indian Evidence Act of 1872 Governing the use and disclosure of protected health information Health Insurance Portability and Accountability Act (HIPAA) Police and Justice Act 2006 Indian Penal Code of 1860 Regulating the collection of personal information from children Children’s Online Privacy Protection Act (COPPA) Investigatory Powers Act 2016 (IPA) A framework for cooperation between countries in investigating and prosecuting cybercrime Regulation of Investigatory Powers Act 2000 (RIPA) Outlining individuals’ legal rights and protections regarding their personal data Personal Data Protection Bill 2019 Measures for the Security Assessment of Cross-border Transfer of Personal Information and Important Data Outlining individuals’ fundamental rights and freedoms State Council Regulation on the Protection of Critical Information Infrastructure Security 2.2.1 USA The Computer Fraud and Abuse Act (CFAA) is a federal law that makes it a criminal offense to access a computer without authorization. It applies to computer-related activities, including hacking, identity theft, and spreading malware. The CFAA has been the focus of much criticism and controversy, with some arguing that its provisions are too far-reaching and could be used to criminalize legitimate security research. In addition, critics have raised the concern that people can interpret the CFAA’s broad definitions of computer-related activities in a manner that could lead to the prosecution of activities that were not intended to be criminal offenses. Furthermore, the CFAA has been criticized for needing more clarity regarding the meaning of specific terms, making it difficult for individuals to understand their rights and responsibilities under the law. For these reasons, it is crucial for individuals to familiarize themselves with the law and to understand the potential implications of their activities. The Digital Millennium Copyright Act (DMCA) includes provisions prohibiting circumventing technological measures to protect copyrighted works. This can consist of digital locks, encryption, and authentication protocols, which safeguard software, firmware, and other types of digital content. Security researchers should know the DMCA provisions to ensure their research activities do not violate the law. It is important to remember that circumventing copyright protection measures, even for research or educational activities, can result in civil or criminal penalties. As such, researchers must exercise caution and due diligence to avoid inadvertently running afoul of the DMCA. The Electronic Communications Privacy Act (ECPA) regulates the interception of electronic communications, including those sent over the Internet. This law makes it unlawful to intercept, access, monitor, or store communications without one or both parties consent. Furthermore, the ECPA prohibits using intercepted communications as evidence in a court of law. The ECPA also outlines the responsibilities of service providers, as they are not allowed to divulge the contents of communications to anyone except the sender and the receiver. Therefore, the ECPA protects the privacy of electronic communications and ensures that individuals are not subjected to illegal interception or use of their communications. The Health Insurance Portability and Accountability Act (HIPAA) governs the use and disclosure of protected health information and includes a set of rules for safeguarding personal health information stored electronically. Researchers should know these requirements and ensure their research activities adhere to HIPAA regulations. This includes taking measures such as encrypting data, keeping detailed data access, and sharing records. Furthermore, research must be conducted by institutional policies and procedures, and the appropriate governance body must approve any changes made. Researchers must also be mindful of the possibility of data breaches and take steps to ensure that any personal health information is kept secure. Failure to comply with HIPAA regulations can result in severe legal and financial penalties, so researchers must ensure that their research activities comply with HIPAA. The Children’s Online Privacy Protection Act (COPPA) is an important piece of legislation regulating the collection of personal information from children under 13. We must be aware of the provisions of COPPA and take precautions to ensure that our research activities do not violate any of the requirements of the Act. To comply with COPPA, researchers must exercise caution and take special steps to ensure that they are not collecting, using, or disclosing any personal information from children under the age of 13. Failure to comply with COPPA could result in legal action and penalties, so security researchers must familiarize themselves with the Act and comply with its provisions. 2.2.2 Europe The General Data Protection Regulation (GDPR) regulates the handling of personal data, strengthens individuals’ rights over personal data, and imposes penalties of up to 4% of global annual revenue or 20 million euros, whichever is higher for non-compliance. Security researchers should be aware of these provisions and ensure that their research does not run afoul of GDPR. It’s important to note that GDPR applies to any company that processes the personal data of EU citizens, regardless of the company’s location. The Network and Information Systems Directive (NISD) requires operators of essential services and digital service providers to take appropriate security measures and report specific incidents. It’s important to note that the NISD applies to various organizations and individuals, including those conducting penetration testing and security research. The Cybercrime Convention of the Council of Europe, the first international treaty on crimes committed via the Internet and other computer networks, provides a framework for cooperation between countries in investigating and prosecuting cybercrime. The E-Privacy Directive 2002/58/EC regulates the processing of personal data in the electronic communication sector. This directive applies to personal processing data in connection with the provision of publicly available electronic communications services in the EU. 2.2.3 UK The Computer Misuse Act 1990 was introduced to address malicious computer usage. It is a criminal offense to access a computer system without authorization, modify data without permission, or misuse computers to commit fraud or other unlawful activities. The Act also allows for confiscating computers and other devices used to commission a computer misuse offense and encourages reporting computer misuse incidents to law enforcement authorities. It also provides for the implementation of various measures to help prevent computer misuse, including establishing a special law enforcement team and implementing appropriate security measures. The Data Protection Act 2018 is an important piece of legislation that provides individuals with certain legal rights and protections regarding their personal data. It details the rights of individuals, such as the right to access their data, the right to have their personal data rectified, and the right to object to the processing of their data. Furthermore, it outlines the obligations of those who process personal data, such as securely and transparently and providing individuals with clear and understandable information about how their data is being used. By considering the Act, security researchers can ensure that their research is conducted responsibly and lawfully. The Human Rights Act 1998 (HRA) is an important piece of legislation in the United Kingdom that outlines individuals’ fundamental rights and freedoms. It incorporates the European Convention on Human Rights into UK law. It ensures that individuals have the right to fair and equal treatment in various areas, such as the right to a fair trial, the right to private and family life, and the right to freedom of expression. It also gives individuals the right to access judicial remedies in cases where their rights have been violated. The Act also gives individuals the right to challenge the legality of any law or administrative action that violates their fundamental rights and freedoms. The HRA is an essential piece of legislation that helps protect individuals from abuse of power and ensures their rights are respected. The Police and Justice Act 2006 was an Act of Parliament passed in the United Kingdom, which aimed to provide a comprehensive framework for reforming the criminal justice system and policing. The Act established several new criminal offenses, including the violation of inciting religious hatred and measures to protect children from exploitation and vulnerable adults. It also provided for the creation of the Serious Organised Crime Agency and a National DNA Database. The Act also set out new measures to tackle anti-social behavior, including introducing Anti-Social Behaviour Orders. Furthermore, it included provisions to modernize the coroners’ system and provide additional powers to the police to combat terrorism. In addition, the Act sought to improve the rights of victims of crime and to provide increased protection for victims of domestic violence. Investigatory Powers Act 2016 (IPA) regulates the use of investigatory powers by law enforcement and intelligence agencies, including hacking and other forms of digital surveillance. The IPA also requires Internet and other communications providers to retain certain data types for a specified period. Regulation of Investigatory Powers Act 2000 (RIPA) regulates public authorities’ use of covert investigatory techniques, including hacking and other forms of digital surveillance. 2.2.4 India The Information Technology Act 2000 provides for legal recognition of transactions using electronic data interchange and other means of electronic communication. It also criminalizes hacking and other unauthorized access to computer systems and imposes penalties for such actions. The Personal Data Protection Bill 2019 is a proposed legislation to protect individuals’ personal data and impose penalties for non-compliance. The Indian Evidence Act of 1872 and the Indian Penal Code of 1860 contain provisions that may be invoked in cases of cybercrime, including hacking and unauthorized access to computer systems. Security researchers should be aware of these laws and ensure our research does not run afoul. 2.2.5 China The Cyber Security Law establishes a legal framework for protecting critical information infrastructure and personal data and requires organizations to comply with certain security measures and report certain types of security incidents. The National Security Law criminalizes activities that threaten national security, including hacking and other unauthorized access to computer systems. The Anti-Terrorism Law criminalizes activities that support or promote terrorism, including hacking and other unauthorized access to computer systems. The Measures for the Security Assessment of Cross-border Transfer of Personal Information and Important Data regulates the cross-border transfer of personal information and important data and also requires organizations to conduct security assessments and obtain approval from relevant authorities before transferring such data. The State Council Regulation on the Protection of Critical Information Infrastructure Security regulates critical information infrastructure protection. Also, it requires organizations to take certain security measures and report certain types of security incidents. 2.2.6 Precautionary Measures during Penetration Tests We have prepared a list of precautions we highly recommend following during each penetration test to avoid violating most laws. In addition, we should also be aware that some countries have additional regulations that apply to specific cases, and we should either inform ourselves or ask our lawyer. ** Precautionary Measure** ☐ Obtain written consent from the owner or authorized representative of the computer or network being tested ☐ Conduct the testing within the scope of the consent obtained only and respect any limitations specified ☐ Take measures to prevent causing damage to the systems or networks being tested ☐ Do not access, use or disclose personal data or any other information obtained during the testing without permission ☐ Do not intercept electronic communications without the consent of one of the parties to the communication ☐ Do not conduct testing on systems or networks that are covered by the Health Insurance Portability and Accountability Act (HIPAA) without proper authorization 2.3 Pre-Engagement Pre-engagement is the stage of preparation for the actual penetration test. During this stage, many questions are asked, and some contractual agreements are made. The client informs us about what they want to be tested, and we explain in detail how to make the test as efficient as possible. The entire pre-engagement process consists of three essential components: Scoping questionnaire Pre-engagement meeting Kick-off meeting Before any of these can be discussed in detail, a Non-Disclosure Agreement (NDA) must be signed by all parties. There are several types of NDAs: Type Description Unilateral NDA This type of NDA obligates only one party to maintain confidentiality and allows the other party to share the information received with third parties. Bilateral NDA In this type, both parties are obligated to keep the resulting and acquired information confidential. This is the most common type of NDA that protects the work of penetration testers. Multilateral NDA Multilateral NDA is a commitment to confidentiality by more than two parties. If we conduct a penetration test for a cooperative network, all parties responsible and involved must sign this document. Exceptions can also be made in urgent cases, where we jump into the kick-off meeting, which can also occur via an online conference. It is essential to know who in the company is permitted to contract us for a penetration test. Because we cannot accept such an order from everyone. Imagine, for example, that a company employee hires us with the pretext of checking the corporate network’s security. However, after we finished the assessment, it turned out that this employee wanted to harm their own company and had no authorization to have the company tested. This would put us in a critical situation from a legal point of view. Below is a sample (not exhaustive) list of company members who may be authorized to hire us for penetration testing. This can vary from company to company, with larger organizations not involving the C-level staff directly and the responsibility falling on IT, Audit, or IT Security senior management or the like. Chief Executive Officer (CEO) Chief Technical Officer (CTO) Chief Information Security Officer (CISO) Chief Security Officer (CSO) Chief Risk Officer (CRO) Chief Information Officer (CIO) VP of Internal Audit Audit Manager VP or Director of IT/Information Security It is vital to determine early on in the process who has signatory authority for the contract, Rules of Engagement documents, and who will be the primary and secondary points of contact, technical support, and contact for escalating any issues. This stage also requires the preparation of several documents before a penetration test can be conducted that must be signed by our client and us so that the declaration of consent can also be presented in written form if required. Otherwise the penetration test could breach the Computer Misuse Act. These documents include, but are not limited to: Document Timing for Creation 1. Non-Disclosure Agreement (NDA) After Initial Contact 2. Scoping Questionnaire Before the Pre-Engagement Meeting 3. Scoping Document During the Pre-Engagement Meeting 4. Penetration Testing Proposal (Contract/Scope of Work (SoW)) During the Pre-engagement Meeting 5. Rules of Engagement (RoE) Before the Kick-Off Meeting 6. Contractors Agreement (Physical Assessments) Before the Kick-Off Meeting 7. Reports During and after the conducted Penetration Test Note: Our client may provide a separate scoping document listing in-scope IP addresses/ranges/URLs and any necessary credentials but this information should also be documented as an appendix in the RoE document. Important Note: These documents should be reviewed and adapted by a lawyer after they have been prepared. 2.3.1 Scoping Questionnaire After initial contact is made with the client, we typically send them a Scoping Questionnaire to better understand the services they are seeking. This scoping questionnaire should clearly explain our services and may typically ask them to choose one or more from the following list: ☐ Internal Vulnerability Assessment ☐ External Vulnerability Assessment ☐ Internal Penetration Test ☐ External Penetration Test ☐ Wireless Security Assessment ☐ Application Security Assessment ☐ Physical Security Assessment ☐ Social Engineering Assessment ☐ Red Team Assessment ☐ Web Application Security Assessment Under each of these, the questionnaire should allow the client to be more specific about the required assessment. Do they need a web application or mobile application assessment? Secure code review? Should the Internal Penetration Test be black box and semi-evasive? Do they want just a phishing assessment as part of the Social Engineering Assessment or also vishing calls? This is our chance to explain the depth and breadth of our services, ensure that we understand our client’s needs and expectations, and ensure that we can adequately deliver the assessment they require. Aside from the assessment type, client name, address, and key personnel contact information, some other critical pieces of information include: How many expected live hosts? How many IPs/CIDR ranges in scope? How many Domains/Subdomains are in scope? How many wireless SSIDs in scope? How many web/mobile applications? If testing is authenticated, how many roles (standard user, admin, etc.)? For a phishing assessment, how many users will be targeted? Will the client provide a list, or we will be required to gather this list via OSINT? If the client is requesting a Physical Assessment, how many locations? If multiple sites are in-scope, are they geographically dispersed? What is the objective of the Red Team Assessment? Are any activities (such as phishing or physical security attacks) out of scope? Is a separate Active Directory Security Assessment desired? Will network testing be conducted from an anonymous user on the network or a standard domain user? Do we need to bypass Network Access Control (NAC)? Finally, we will want to ask about information disclosure and evasiveness (if applicable to the assessment type): Is the Penetration Test black box (no information provided), grey box (only IP address/CIDR ranges/URLs provided), white box (detailed information provided) Would they like us to test from a non-evasive, hybrid-evasive (start quiet and gradually become “louder” to assess at what level the client’s security personnel detect our activities), or fully evasive. This information will help us ensure we assign the right resources and deliver the engagement based on the client’s expectations. This information is also necessary for providing an accurate proposal with a project timeline (for example, a Vulnerability Assessment will take considerably less time than a Red Team Assessment) and cost (an External Penetration Test against 10 IPs will cost significantly less than an Internal Penetration Test with 30 /24 networks in-scope). Based on the information we received from the scoping questionnaire, we create an overview and summarize all information in the Scoping Document. 2.3.2 Pre-Engagement Meeting Once we have an initial idea of the client’s project requirements, we can move on to the pre-engagement meeting. This meeting discusses all relevant and essential components with the customer before the penetration test, explaining them to our customer. The information we gather during this phase, along with the data collected from the scoping questionnaire, will serve as inputs to the Penetration Testing Proposal, also known as the Contract or Scope of Work (SoW). We can think of the whole process as a visit to the doctor to inform ourselves regarding the planned examinations. This phase typically occurs via e-mail and during an online conference call or in-person meeting. Note: We may encounter clients during our career that are undergoing their first ever penetration test, or the direct client PoC is not familiar with the process. It is not uncommon to use part of the pre-engagement meeting to review the scoping questionnaire either in part or step-by-step. 2.3.2.1 Contract - Checklist Checkpoint Description ☐ NDA Non-Disclosure Agreement (NDA) refers to a secrecy contract between the client and the contractor regarding all written or verbal information concerning an order/project. The contractor agrees to treat all confidential information brought to its attention as strictly confidential, even after the order/project is completed. Furthermore, any exceptions to confidentiality, the transferability of rights and obligations, and contractual penalties shall be stipulated in the agreement. The NDA should be signed before the kick-off meeting or at the latest during the meeting before any information is discussed in detail. ☐ Goals Goals are milestones that must be achieved during the order/project. In this process, goal setting is started with the significant goals and continued with fine-grained and small ones. ☐ Scope The individual components to be tested are discussed and defined. These may include domains, IP ranges, individual hosts, specific accounts, security systems, etc. Our customers may expect us to find out one or the other point by ourselves. However, the legal basis for testing the individual components has the highest priority here. ☐ Penetration Testing Type When choosing the type of penetration test, we present the individual options and explain the advantages and disadvantages. Since we already know the goals and scope of our customers, we can and should also make a recommendation on what we advise and justify our recommendation accordingly. Which type is used in the end is the client’s decision. ☐ Methodologies Examples: OSSTMM, OWASP, automated and manual unauthenticated analysis of the internal and external network components, vulnerability assessments of network components and web applications, vulnerability threat vectorization, verification and exploitation, and exploit development to facilitate evasion techniques. ☐ Penetration Testing Locations External: Remote (via secure VPN) and/or Internal: Internal or Remote (via secure VPN) ☐ Time Estimation For the time estimation, we need the start and the end date for the penetration test. This gives us a precise time window to perform the test and helps us plan our procedure. It is also vital to explicitly ask how time windows the individual attacks (Exploitation / Post-Exploitation / Lateral Movement) are to be carried out. These can be carried out during or outside regular working hours. When testing outside regular working hours, the focus is more on the security solutions and systems that should withstand our attacks. ☐ Third Parties For the third parties, it must be determined via which third-party providers our customer obtains services. These can be cloud providers, ISPs, and other hosting providers. Our client must obtain written consent from these providers describing that they agree and are aware that certain parts of their service will be subject to a simulated hacking attack. It is also highly advisable to require the contractor to forward the third-party permission sent to us so that we have actual confirmation that this permission has indeed been obtained. ☐ Evasive Testing Evasive testing is the test of evading and passing security traffic and security systems in the customer’s infrastructure. We look for techniques that allow us to find out information about the internal components and attack them. It depends on whether our contractor wants us to use such techniques or not. ☐ Risks We must also inform our client about the risks involved in the tests and the possible consequences. Based on the risks and their potential severity, we can then set the limitations together and take certain precautions. ☐ Scope Limitations &amp; Restrictions It is also essential to determine which servers, workstations, or other network components are essential for the client’s proper functioning and its customers. We will have to avoid these and must not influence them any further, as this could lead to critical technical errors that could also affect our client’s customers in production. ☐ Information Handling HIPAA, PCI, HITRUST, FISMA/NIST, etc. ☐ Contact Information For the contact information, we need to create a list of each person’s name, title, job title, e-mail address, phone number, office phone number, and an escalation priority order. ☐ Lines of Communication It should also be documented which communication channels are used to exchange information between the customer and us. This may involve e-mail correspondence, telephone calls, or personal meetings. ☐ Reporting Apart from the report’s structure, any customer-specific requirements the report should contain are also discussed. In addition, we clarify how the reporting is to take place and whether a presentation of the results is desired. ☐ Payment Terms Finally, prices and the terms of payment are explained. The most crucial element of this meeting is the detailed presentation of the penetration test to our client and its focus. As we already know, each piece of infrastructure is unique for the most part, and each client has particular preferences on which they place the most importance. Finding out these priorities is an essential part of this meeting. We can think of it as ordering in a restaurant. If we want a medium-rare steak and the chef gives us a well-done steak because he believes it is better, it will not be what we were hoping for. Therefore, we should prioritize our client’s wishes and serve the steak as they ordered. Based on the Contract Checklist and the input information shared in scoping, the Penetration Testing Proposal (Contract) and the associated Rules of Engagement (RoE) are created. 2.3.2.2 Rules of Engagement - Checklist Checkpoint Contents ☐ Introduction Description of this document. ☐ Contractor Company name, contractor full name, job title. ☐ Penetration Testers Company name, pentesters full name. ☐ Contact Information Mailing addresses, e-mail addresses, and phone numbers of all client parties and penetration testers. ☐ Purpose Description of the purpose for the conducted penetration test. ☐ Goals Description of the goals that should be achieved with the penetration test. ☐ Scope All IPs, domain names, URLs, or CIDR ranges. ☐ Lines of Communication Online conferences or phone calls or face-to-face meetings, or via e-mail. ☐ Time Estimation Start and end dates. ☐ Time of the Day to Test Times of the day to test. ☐ Penetration Testing Type External/Internal Penetration Test/Vulnerability Assessments/Social Engineering. ☐ Penetration Testing Locations Description of how the connection to the client network is established. ☐ Methodologies OSSTMM, PTES, OWASP, and others. ☐ Objectives / Flags Users, specific files, specific information, and others. ☐ Evidence Handling Encryption, secure protocols ☐ System Backups Configuration files, databases, and others. ☐ Information Handling Strong data encryption ☐ Incident Handling and Reporting Cases for contact, pentest interruptions, type of reports ☐ Status Meetings Frequency of meetings, dates, times, included parties ☐ Reporting Type, target readers, focus ☐ Retesting Start and end dates ☐ Disclaimers and Limitation of Liability System damage, data loss ☐ Permission to Test Signed contract, contractors agreement 2.3.3 Kick-Off Meeting The kick-off meeting usually occurs at a scheduled time and in-person after signing all contractual documents. This meeting usually includes client POC(s) (from Internal Audit, Information Security, IT, Governance &amp; Risk, etc., depending on the client), client technical support staff (developers, sysadmins, network engineers, etc.), and the penetration testing team (someone in a management role (such as the Practice Lead), the actual penetration tester(s), and sometimes a Project Manager or even the Sales Account Executive or similar). We will go over the nature of the penetration test and how it will take place. Usually, there is no Denial of Service (DoS) testing. We also explain that if a critical vulnerability is identified, penetration testing activities will be paused, a vulnerability notification report will be generated, and the emergency contacts will be contacted. Typically these are only generated during External Penetration Tests for critical flaws such as unauthenticated remote code execution (RCE), SQL injection, or another flaw that leads to sensitive data disclosure. The purpose of this notification is to allow the client to assess the risk internally and determine if the issue warrants an emergency fix. We would typically only stop an Internal Penetration Test and alert the client if a system becomes unresponsive, we find evidence of illegal activity (such as illegal content on a file share) or the presence of an external threat actor in the network or a prior breach. We must also inform our customers about potential risks during a penetration test. For example, we should mention that a penetration test can leave many log entries and alarms in their security applications. In addition, if brute forcing or any similar attack is used, it is also worth mentioning that we may accidentally lock some users found during the penetration test. We also must inform our customers that they must contact us immediately if the penetration test performed negatively impacts their network. Explaining the penetration testing process gives everyone involved a clear idea of our entire process. This demonstrates our professional approach and convinces our questioners that we know what we are doing. Because apart from the technical staff, CTO, and CISO, it will sound like a certain kind of magic that is very difficult for non-technical professionals to understand. So we must be mindful of our audience and target the most technically inexperienced questioner so our approach can be followed by everyone we talk to. All points related to testing need to be discussed and clarified. It is crucial to respond precisely to the wishes and expectations of the customer/client. Every company structure and network is different and requires an adapted approach. Each client has different goals, and we should adjust our testing to their wishes. We can typically see how experienced our clients are in undergoing penetration tests early in the call, so we may have to shift our focus to explain things in more detail and be prepared to field more questions, or the kickoff call may be very quick and straightforward. 2.3.4 Contractors Agreement If the penetration test also includes physical testing, then an additional contractor’s agreement is required. Since it is not only a virtual environment but also a physical intrusion, completely different laws apply here. It is also possible that many of the employees have not been informed about the test. Suppose we encounter employees with a very high-security awareness during the physical attack and social engineering attempts, and we get caught. In that case, the employees will, in most cases, contact the police. This additional contractor's agreement is our “get out of jail free card” in this case. 2.3.4.1 Contractors Agreement - Checklist for Physical Assessments Checkpoint ☐ Introduction ☐ Contractor ☐ Purpose ☐ Goal ☐ Penetration Testers ☐ Contact Information ☐ Physical Addresses ☐ Building Name ☐ Floors ☐ Physical Room Identifications ☐ Physical Components ☐ Timeline ☐ Notarization ☐ Permission to Test 2.3.5 Setting Up After all the above points have been worked through, and we have the necessary information, we plan our approach and prepare everything. We will find that the penetration test results are still unknown, but we can prepare our VMs, VPS, and other tools/systems for all scenarios and situations. More information and how to prepare these systems can be found in the Setting Up module. 2.4 Information Gathering Once the pre-engagement phase has been completed, and all parties have signed all contractual terms and conditions, the information gathering phase begins. Information gathering is an essential part of any security assessment. This is the phase in which we gather all available information about the company, its employees and infrastructure, and how they are organized. Information gathering is the most frequent and vital phase throughout the penetration testing process, to which we will return again and again. All the steps we take to exploit the vulnerabilities are based on the information we enumerate about our targets. This phase can be considered the cornerstone of any penetration test. We can obtain the necessary information relevant to us in many different ways. However, we can divide them into the following categories: Open-Source Intelligence Infrastructure Enumeration Service Enumeration Host Enumeration All four categories should and must be performed by us for each penetration test. This is because the information is the main component that leads us to successful penetration testing and identifying security vulnerabilities. We can get this information anywhere, whether on social media, job postings, individual hosts and servers, or even the employees. Information is continually being spread and shared everywhere. After all, we humans communicate by exchanging information, but network components and services communicate similarly. Any exchange of information always has a specific purpose. For computer networks, the aim is always to trigger a particular process. Be it storing data in a database, registering, generating specific values, or forwarding the information. 2.4.1 Open-Source Intelligence Let’s assume that our client wants us to see what information we can find about his company on the internet. For this purpose, we use what is known as Open Source Intelligence (OSINT). OSINT is a process for finding publicly available information on a target company or individuals that allows the identification of events (i.e., public and private meetings), external and internal dependencies, and connections. OSINT uses public (Open-Source) information from freely available sources to obtain the desired results. We can often find security-relevant and sensitive information from companies and their employees. Usually, the people who share such information are unaware that they are not the only ones who can access it. It is possible to find highly sensitive information such as passwords, hashes, keys, tokens, and much more that can give us access to the network within just a few minutes. Repositories on sites like Github or other development platforms are often not set up correctly, and external viewers can see this information. If this type of sensitive information is found at the onset of testing, the Incident Handling and Report section of the RoE should describe the procedure for reporting these types of critical security vulnerabilities. Publicly published passwords or SSH keys represent a critical security gap if they have not already been removed or changed. Therefore, our client’s administrator must review this information before we proceed. 2.4.1.1 Private and Public SSH Keys Developers often share whole sections of code on StackOverflow to show other developers a better overview of how their code works to help them solve their problems. This type of information can also be found very quickly and used against the company. Our task is to find such security holes and have them closed. We can learn much more from the OSINT: Corporate Recon module. It shows many different techniques for how we can find such information. 2.4.2 Infrastructure Enumeration During the infrastructure enumeration, we try to overview the company’s position on the internet and intranet. For this, we use OSINT and the first active scans. We use services such as DNS to create a map of the client’s servers and hosts and develop an understanding of how their infrastructure is structured. This includes name servers, mail servers, web servers, cloud instances, and more. We make an accurate list of hosts and their IP addresses and compare them to our scope to see if they are included and listed. In this phase, we also try to determine the company’s security measures. The more precise this information is, the easier it will be to disguise our attacks (Evasive Testing). But identifying firewalls, such as web application firewalls, also gives us an excellent understanding of what techniques could trigger an alarm for our customer and what methods can be used to avoid that alarm. Here, it also does not matter “where” we are positioned, whether we are trying to gain an overview of the infrastructure from the outside (external) or examining the infrastructure from the inside (internal) of the network. Enumeration from inside the network gives us a good overview of the hosts and servers that we can use as targets for a Password Spraying attack, in which we use one password to attempt to authenticate with as many different user names as possible, hoping for one successful authentication attempt to grant us a foothold in the network. All these methods and techniques used for this purpose will be looked at in more detail in the individual modules. 2.4.3 Service Enumeration In service enumeration, we identify services that allow us to interact with the host or server over the network (or locally, from an internal perspective). Therefore, it is crucial to find out about the service, what version it is, what information it provides us, and the reason it can be used. Once we understand the background of what this service has been provisioned for, some logical conclusions can be drawn to provide us with several options. Many services have a version history that allows us to identify whether the installed version on the host or server is actually up to date or not. This will also help us find security vulnerabilities that remain with older versions in most cases. Many administrators are afraid to change applications that work, as it could harm the entire infrastructure. Therefore, administrators often prefer to accept the risk of leaving one or more vulnerabilities open and maintaining the functionality instead of closing the security gaps. 2.4.4 Host Enumeration Once we have a detailed list of the customer’s infrastructure, we examine every single host listed in the scoping document. We try to identify which operating system is running on the host or server, which services it uses, which versions of the services, and much more. Again, apart from the active scans, we can also use various OSINT methods to tell us how this host or server may be configured. We can find many different services, such as an FTP server that the company uses to exchange data between employees and even allows anonymous access. Even today, there are many hosts and servers that the manufacturers no longer support. However, vulnerabilities are still found for these older versions of operating systems and services, which then remain and endanger our client’s entire infrastructure. It does not matter here whether we examine each host or server externally or internally. However, from the internal perspective, we will find services that are often not accessible from the outside. Therefore, many administrators become careless and often consider these services “secure” because they are not directly accessible from the internet. Thus, many misconfigurations are often discovered here due to these assumptions or lax practices. During host enumeration, we try to determine what role this host or server plays and what network components it communicates with. In addition, we must also identify which services it uses for this purpose and on which ports they are located. During internal host enumeration, which in most cases comes after the successful Exploitation of one or more vulnerabilities, we also examine the host or server from the inside. This means we look for sensitive files, local services, scripts, applications, information, and other things that could be stored on the host. This is also an essential part of the Post-Exploitation phase, where we try to exploit and elevate privileges. 2.4.5 Pillaging Another essential step is Pillaging. After hitting the Post-Exploitation stage, pillaging is performed to collect sensitive information locally on the already exploited host, such as employee names, customer data, and much more. However, this information gathering only occurs after exploiting the target host and gaining access to it. The information we can obtain on the exploited hosts can be divided into many different categories and varies greatly. This depends on the purpose of the host and its positioning in the corporate network. The administrators taking the security measures for these hosts also play a significant role. Nevertheless, such information can show the impact of a potential attack on our client and be used for further steps to escalate our privileges or move laterally further in the network. Note that HTB Academy does not have a module explicitly focused on pillaging. This is intentional for reasons we will clarify here. Pillaging alone is not a stage or a subcategory as many often describe but an integral part of the information gathering and privilege escalation stages that is inevitably performed locally on target systems. Pillaging is explained in other modules separately, where we consider the corresponding steps valuable and necessary. Here is a small list of modules where Pillaging is covered, but this topic will be covered in many other modules as well: Network Enumeration with Nmap Getting Started Password Attacks Active Directory Enumeration &amp; Attacks Linux Privilege Escalation Windows Privilege Escalation Attacking Common Services Attacking Common Applications Attacking Enterprise Networks We will interact with more than 150 targets during the Penetration Tester Job Role Path and perform nine simulated mini penetration tests, giving us plenty of opportunities to work on and practice this topic. Furthermore, operating system-specific modules should be considered from the pillaging point of view because much of what is shown in those modules can be used for information retrieval or privilege escalation on the target systems. 2.5 Vulnerability Assessment During the vulnerability assessment phase, we examine and analyze the information gathered during the information gathering phase. The vulnerability assessment phase is an analytical process based on the findings. An analysis is a detailed examination of an event or process, describing its origin and impact, that with the help of certain precautions and actions, can be triggered to support or prevent future occurrences. Any analysis can be very complicated, as many different factors and their interdependencies play a significant role. Apart from the fact that we work with the three different times (past, present, and future) during each analysis, the origin and destination play a significant role. There are four different types of analysis: Analysis Type Description Descriptive Descriptive analysis is essential in any data analysis. On the one hand, it describes a data set based on individual characteristics. It helps to detect possible errors in data collection or outliers in the data set. Diagnostic Diagnostic analysis clarifies conditions’ causes, effects, and interactions. Doing so provides insights that are obtained through correlations and interpretation. We must take a backward-looking view, similar to descriptive analysis, with the subtle difference that we try to find reasons for events and developments. Predictive By evaluating historical and current data, predictive analysis creates a predictive model for future probabilities. Based on the results of descriptive and diagnostic analyses, this method of data analysis makes it possible to identify trends, detect deviations from expected values at an early stage, and predict future occurrences as accurately as possible. Prescriptive Prescriptive analytics aims to narrow down what actions to take to eliminate or prevent a future problem or trigger a specific activity or process. We use our results and information obtained so far and analyze them to make conclusions. The formation of conclusions can be extended very far, but we must then confirm or disprove them. Suppose we found an open TCP port 2121 on a host during the information-gathering phase. Other than the fact that this port is open, Nmap did not show us anything else. We must now ask ourselves what conclusions can be drawn from this result. Therefore, it does not matter which question we start with to make our conclusions. However, it is essential to ask precise questions and remember what we know and do not know. At this point, we must first ask ourselves what we see and what we actually have, because what we see is not the same as what we have: a TCP port 2121. - TCP already means that this service is connection-oriented. Is this a standard port? - No, because these are between 0-1023, aka well-known or system ports Are there any numbers in this port number that look familiar? - Yes, TCP port 21 (FTP). From our experience, we will get to know many standard ports and their services, which administrators often try to disguise, but often use “easy to remember” alternatives. Based on our guess, we can try to connect to the service using Netcat or an FTP client and try to establish a connection to confirm or disprove our guess. While connecting to the service, we noticed that the connection took longer than usual (about 15 seconds). There are some services whose connection speed, or response time, can be configured. Now that we know that an FTP server is running on this port, we can deduce the origin of our “failed” scan. We could confirm this again by specifying the minimum probe round trip time (--min-rtt-timeout) in Nmap to 15 or 20 seconds and rerunning the scan. 2.5.1 Vulnerability Research and Analysis Information Gathering and Vulnerability Research can be considered a part of descriptive analysis. This is where we identify the individual network or system components we are investigating. In Vulnerability Research, we look for known vulnerabilities, exploits, and security holes that have already been discovered and reported. Therefore, if we have identified a version of a service or application through information gathering and found a Common Vulnerabilities and Exposures (CVE), it is very likely that this vulnerability is still present. We can find vulnerability disclosures for each component using many different sources. These include, but are not limited to: CVEdetails Exploit DB Vulners Packet Storm Security NIST This is where Diagnostic Analysis and Predictive Analysis is used. Once we have found a published vulnerability like this, we can diagnose it to determine what is causing or has caused the vulnerability. Here, we must understand the functionality of the Proof-Of-Concept (POC) code or the application or service itself as best as possible, as many manual configurations by administrators will require some customization for the POC. Each POC is tailored to a specific case that we will also need to adapt to ours in most cases. 2.5.2 Assessment of Possible Attack Vectors Vulnerability Assessment also includes the actual testing, which is part of Predictive Analysis. In doing so, we analyze historical information and combine it with the current information that we have been able to find out. Whether we have received specific evasion level requirements from our client, we test the services and applications found locally or on the target system. If we have to test covertly and avoid alerts, we should mirror the target system locally as precisely as possible. This means we use the information obtained during our information gathering phase to replicate the target system and then look for vulnerabilities in the locally deployed system. 2.5.3 The Return Suppose we are unable to detect or identify potential vulnerabilities from our analysis. In that case, we will return to the Information Gathering stage and look for more in-depth information than we have gathered so far. It is important to note that these two stages (Information Gathering and Vulnerability Assessment) often overlap, resulting in regular back and forth movement between them. We will see this in many videos where the author is solving an HTB box or some CTF challenge. We should remember that these challenges are often solved as fast as possible, and therefore speed is more important than quality. In a CTF, the goal is to get on the target machine and capture the flags with the highest privileges as fast as possible instead of exposing all potential weaknesses in the system. A (real) Penetration Test is not a CTF. Here the quality and intensity of our penetration test and its analysis have the highest priority because nothing is worse if our client gets successfully hacked via a relatively simple vector that we should have uncovered during our penetration test. 2.6 Explotation During the Exploitation stage, we look for ways that these weaknesses can be adapted to our use case to obtain the desired role (i.e., a foothold, escalated privileges, etc.). If we want to get a reverse shell, we need to modify the PoC to execute the code, so the target system connects back to us over (ideally) an encrypted connection to an IP address we specify. Therefore, the preparation of an exploit is mainly part of the Exploitation stage. These stages should not be strictly separated from each other, as they are closely connected. Nevertheless, it is still important to distinguish which phase we are in and its purpose. Because later, with much more complex processes and much more information, it is very easy to lose track of the steps that have been taken, especially if the penetration test lasts several weeks and covers a massive scope. 2.6.1 Prioritization of Possible Attacks Once we have found one or two vulnerabilities during the Vulnerability Assessment stage that we can apply to our target network/system, we can prioritize those attacks. Which of those attacks we prioritize higher than the others depends on the following factors: Probability of Success Complexity Probability of Damage First, we need to assess the probability of successfully executing a particular attack against the target. CVSS Scoring can help us here, using the NVD calculator better to calculate the specific attacks and their probability of success. Complexity represents the effort of exploiting a specific vulnerability. This is used to estimate how much time, effort, and research is required to execute the attack on the system successfully. Our experience plays an important role here because if we are to carry out an attack that we have never used before, this will logically require much more research and effort since we must understand the attack and the exploit structure in detail before applying it. Estimating the probability of damage caused by the execution of an exploit plays a critical role, as we must avoid any damage to the target systems. Generally, we do not perform DoS attacks unless our client requires them. Nevertheless, attacking the running services live with exploits that can cause damage to the software or the operating system is something that we must avoid at all times. In addition, we can assign these factors to a personal point system which will allow the evaluation to be more accurately calculated based on our skills and knowledge: 2.6.1.1 Prioritization Example Factor Points Remote File Inclusion Buffer Overflow 1. Probability of Success 10 10 8 2. Complexity - Easy 5 4 0 3. Complexity - Medium 3 0 3 4. Complexity - Hard 1 0 0 5. Probability of Damage -5 0 -5 Summary max. 15 14 6 Based on the above example, we would prefer the remote file inclusion attack. It is easy to prepare and execute and should not cause any damage if approached carefully. 2.6.2 Preparation for the Attack Sometimes we will run into a situation where we can’t find high-quality, known working PoC exploit code. Therefore, it may be necessary to reconstruct the exploit locally on a VM representing our target host to figure out precisely what needs to be adapted and changed. Once we have set up the system locally and installed known components to mirror the target environment as closely as possible (i.e., same version numbers for target services/applications), we can start preparing the exploit by following the steps described in the exploit. Then we test this on a locally hosted VM to ensure it works and does not damage significantly. In other situations, we will encounter misconfigurations and vulnerabilities that we see very often and know exactly which tool or exploit to use and whether the exploit or technique is “safe” or can cause instability. If ever in doubt before running an attack, it’s always best to check with our client, providing them all necessary data so they can make an informed decision on whether they would like us to attempt exploitation or just mark the finding as an issue. If they opt for us not to proceed with exploitation, we can note in the report that it was not confirmed actively but is likely an issue that needs to be addressed. We have a certain amount of leeway during penetration tests and should always use our best judgment if a particular attack seems too risky or could potentially cause a disruption. When in doubt, communicate. Your team lead/manager, the client, will almost certainly prefer extra communication than run into a situation where they are trying to bring a system back online after a failed exploit attempt. Once we have successfully exploited a target and have initial access (and taken clear notes for our reports and logged all activities in our activity log!), we’ll move on to the post-exploitation and lateral movement stages. 2.7 Post-Explotation Let’s assume we successfully exploited the target system during the Exploitation stage. As with the Exploitation stage, we must again consider whether or not to utilize Evasive Testing in the Post-Exploitation stage. We are already on the system in the post-exploitation phase, making it much more difficult to avoid an alert. The Post-Exploitation stage aims to obtain sensitive and security-relevant information from a local perspective and business-relevant information that, in most cases, requires higher privileges than a standard user. This stage includes the following components: Evasive Testing Information Gathering Pillaging Vulnerability Assessment Privilege Escalation Persistence Data Exfiltration 2.7.1 Evasive Testing If a skilled administrator monitors the systems, any change or even a single command could trigger an alarm that will give us away. In many cases, we get kicked out of the network, and then threat hunting begins where we are the focus. We may also lose access to a host (that gets quarantined) or a user account (that gets temporarily disabled or the password changed). This penetration test would have failed but succeeded in some ways because the client could detect some actions. We can provide value to the client in this situation by still writing up an entire attack chain and helping them identify gaps in their monitoring and processes where they did not notice our actions. For us, we can study how and why the client detected us and work on improving our evasion skills. Perhaps we did not thoroughly test a payload, or we got careless and ran a command such as net user or whoami that is often monitored by EDR systems and flagged as anomalous activity.  It can often help our clients if we run commands or tools that their defenses stop or detect. It shows them that their defenses are working on some attacks. Keep in mind that we are emulating an attacker, so it’s not always entirely bad for some of the attacks to get noticed. Though when performing evasive testing, our goal should be to go mostly undetected so we can identify any “blind spots” our clients have in their network environments. Evasive testing is divided into three different categories: Evasive Hybrid Evasive Non-Evasive This does not mean that we cannot use all three methods. Suppose our client wants to perform an intrusive penetration test to get as much information as possible and the most in-depth testing results. In that case, we will perform Non-Evasive Testing, as the security measures around the network may limit and even stop us. However, this can also be combined with Evasive testing, using the same commands and methods for non-evasive testing. We can then see if the security measures can identify and respond to the actions performed. In Hybrid-Evasive testing, we can test specific components and security measures that have been defined in advance. This is common when the customer only wants to test specific departments or servers to see if they can withstand the attacks. 2.7.2 Information Gathering Since we have gained a new perspective on the system and the network of our target system in the Exploitation stage, we are basically in a new environment. This means we first have to reacquaint ourselves with what we are working with and what options are available. Therefore, in the Post-Exploitation stage, we go through the Information Gathering and Vulnerability Assessment stages again, which we can consider as parts of the current stage. This is because the information we had up to this point was gathered from an external perspective, not an internal one. From the inside (local) perspective, we have many more possibilities and alternatives to access certain information that is relevant to us. Therefore, the information gathering stage starts all over again from the local perspective. We search and gather as much information as we can. The difference here is that we also enumerate the local network and local services such as printers, database servers, virtualization services, etc. Often we will find shares intended for employees to use to exchange and share data and files. The investigation of these services and network components is called Pillaging. 2.7.3 Pillaging Pillaging is the stage where we examine the role of the host in the corporate network. We analyze the network configurations, including but not limited to: Interfaces Routing DNS ARP Services VPN IP Subnets Shares Network Traffic Understanding the role of the system we are on also gives us an excellent understanding of how it communicates with other network devices and its purpose. From this, we can find out, for example, what alternative subdomains exist, whether it has multiple network interfaces, whether there are other hosts with which this system communicates, if admins are connecting to other hosts from it, and if we can potentially reuse credentials or steal an SSH key to further our access or establish persistence, etc. This helps, above all, to get an overview of the network’s structure. For example, we can use the policies installed on this system to determine what other hosts are using on the network. Because administrators often use particular schemas to secure their network and prevent users from changing anything on it. For example, suppose we discover that the password policy requires only eight characters but no special characters. In that case, we can conclude that we have a relatively high probability of guessing other users’ passwords on this and other systems. During the pillaging stage, we will also hunt for sensitive data such as passwords on shares, local machines, in scripts, configuration files, password vaults, documents (Excel, Word, .txt files, etc.), and even email. Our main goals with pillaging are to show the impact of successful exploitation and, if we have not yet reached the goal of the assessment, to find additional data such as passwords that can be inputs to other stages such as lateral movement. 2.7.4 Persistence Once we have an overview of the system, our immediate next step is maintaining access to the exploited host. This way, if the connection is interrupted, we can still access it. This step is essential and often used as the first step before the Information Gathering and Pillaging stages. We should follow non-standardized sequences because each system is individually configured by a unique administrator who brings their own preferences and knowledge. It is recommended that we work flexibly during this phase and adapt to the circumstances. For example, suppose we have used a buffer overflow attack on a service that is likely to crash it. In that case, we should establish persistence to the system as soon as possible to avoid having to attack the service multiple times and potentially causing a disruption. Often if we lose the connection, we will not be able to access the system in the same way. 2.7.5 Vulnerability Assessment If we can maintain access and have a good overview of the system, we can use the information about the system and its services and any other data stored on it to repeat the Vulnerability Assessment stage, but this time from inside the system. We analyze the information and prioritize it accordingly. The goal we pursue next is the escalation of privileges (if not already in place). Again, it is essential to distinguish between exploits that can harm the system and attacks against the services that do not cause any disruption. In doing so, we weigh the components we have already gone through in the first Vulnerability Assessment stage. 2.7.6 Privilege Escalation Privilege escalation is significant, and in most cases, it represents a critical moment that can open many more new doors for us. Getting the highest possible privileges on the system or domain is often crucial. Therefore we want to get the privileges of the root (on Linux-based systems) or the domain administrator/local administrator/SYSTEM (on Windows-based systems) because this will often allow us to move through the entire network without any restrictions. However, it is essential to remember that the escalation of privileges does not always have to occur locally on the system. We can also obtain stored credentials during the information gathering stage from other users who are members of a higher privileged group. Exploiting these privileges to log in as another user is also part of privilege escalation because we have escalated our privileges (quickly) using the new set of credentials. 2.7.7 Data Exfiltration During the Information Gathering and Pillaging stage, we will often be able to find, among other things, considerable personal information and customer data. Some clients will want to check whether it is possible to exfiltrate these types of data. This means we try to transfer this information from the target system to our own. Security systems such as Data Loss Prevention (DLP) and Endpoint Detection and Response (EDR) help detect and prevent data exfiltration. In addition to Network Monitoring, many companies use encryption on hard drives to prevent external parties from viewing such information. Before exfiltrating any actual data, we should check with the customer and our manager. It can often be enough to create some bogus data (such as fake credit card numbers or social security numbers) and exfiltrate it to our system. That way, the protection mechanisms that look for patterns in data leaving the network will be tested, but we will not be responsible for any live sensitive data on our testing machine. Companies must adhere to data security regulations depending on the type of data involved. These include, but are not limited to: Type of Information Security Regulation Credit Card Account Information Payment Card Industry (PCI) Electronic Patient Health Information Health Insurance Portability and Accountability Act (HIPAA) Consumers Private Banking Information Gramm-Leach-Bliley (GLBA) Government Information Federal Information Security Management Act of 2002 (FISMA) Some frameworks companies may follow include: (NIST) - National Institute of Standards and Technology (CIS Controls) - Center for Internet Security Controls (ISO) - International Organization for Standardization (PCI-DSS) - The Payment Card Industry Data Security Standard (GDPR) - General Data Protection Regulation (COBIT) - Control Objectives for Information and Related Technologies (FedRAMP) - The Federal Risk and Authorization Management Program (ITAR) - International Traffic in Arms Regulations (AICPA) - American Institute of Certified Public Accountants (NERC CIP Standards) - NERC Critical Infrastructure Protection Standards It is worth familiarizing ourselves with each of these frameworks but what is crucial for us, however, is how we handle this information. For us, the type of data does not have much significance, but the required controls around it do, and as stated previously, we can simulate exfiltrating data from the network as a proof of concept that it is possible. We should check with the client to ensure that their systems are intended to catch the fake data type that we attempt to exfiltrate if we are successful, so we do not misrepresent anything in our report. It’s a good habit to run a screen recording (along with taking screenshots) as additional evidence for such vital steps. If we only have terminal access, we can display the hostname, IP address, user name, and the corresponding path to the customer file and take a screenshot or screen capture. This helps us prove where the data originated from and that we could remove it from the environment successfully. If sensitive data like this is found, our client should, of course, be informed immediately. Based on the fact that we could escalate the privileges and exfiltrate personal data, they may want to pause, end, or shift the focus of the penetration test, especially if data exfiltration was the primary goal. However, this is at our client’s discretion, and many will prefer that we keep testing to identify all possible weaknesses in their environment. Next, we’ll discuss lateral movement, a key stage in the penetration testing process that may use data from our post-exploitation as an input. 2.8 Lateral Movement If everything went well and we were able to penetrate the corporate network (Exploitation) successfully, gather locally stored information, and escalate our privileges (Post-Exploitation), we next enter the Lateral Movement stage. The goal here is that we test what an attacker could do within the entire network. After all, the main goal is not only to successfully exploit a publicly available system but also to get sensitive data or find all ways that an attacker could render the network unusable. One of the most common examples is ransomware. If a system in the corporate network is infected with ransomware, it can spread across the entire network. It locks down all the systems using various encryption methods, making them unusable for the whole company until a decryption key is entered. In the most common cases, the company is financially extorted to make a profit. Often, it is only at this moment that companies realize how important IT security is. If they had had a good penetration tester who had tested things (and proper processes and layered defenses in place), they probably could have prevented such a situation and the financial (if not legal) damage. It is often forgotten that in many countries, the CEOs are held liable for not securing their customer data appropriately. In this stage, we want to test how far we can move manually in the entire network and what vulnerabilities we can find from the internal perspective that might be exploited. In doing so, we will again run through several phases: Pivoting Evasive Testing Information Gathering Vulnerability Assessment (Privilege) Exploitation Post-Exploitation As seen in the graphic above, we can move to this stage from the Exploitation and the Post-Exploitation stage. Sometimes we may not find a direct way to escalate our privileges on the target system itself, but we have ways to move around the network. This is where Lateral Movement comes into play. 2.8.1 Pivoting In most cases, the system we use will not have the tools to enumerate the internal network efficiently. Some techniques allow us to use the exploited host as a proxy and perform all the scans from our attack machine or VM. In doing so, the exploited system represents and routes all our network requests sent from our attack machine to the internal network and its network components. In this way, we make sure that non-routable networks (and therefore publicly unreachable) can still be reached. This allows us to scan them for vulnerabilities and penetrate deeper into the network. This process is also known as Pivoting or Tunneling. An elementary example could be that we have a printer at home that is not accessible from the Internet, but we can send print jobs from our home network. If one of the hosts on our home network has been compromised, it could be leveraged to send these jobs to the printer. Though this is a simple (and unlikely) example, it illustrates the goal of pivoting, which is to access inaccessible systems via an intermediary system. 2.8.2 Evasive Testing Also, at this stage, we should consider whether evasive testing is part of the assessment scope. There are different procedures for each tactic, which support us in disguising these requests to not trigger an internal alarm among the administrators and the blue team. There are many ways to protect against lateral movement, including network (micro) segmentation, threat monitoring, IPS/IDS, EDR, etc. To bypass these efficiently, we need to understand how they work and what they respond to. Then we can adapt and apply methods and strategies that help avoid detection. 2.8.3 Information Gathering Before we target the internal network, we must first get an overview of which systems and how many can be reached from our system. This information may already be available to us from the last post-exploitation stage, where we took a closer look at the settings and configurations of the system. We return to the Information Gathering stage, but this time, we do it from inside the network with a different view of it. Once we have discovered all hosts and servers, we can enumerate them individually. 2.8.4 Vulnerability Assessment Vulnerability assessment from the inside of the network differs from the previous procedures. This is because far more errors occur inside a network than on hosts and servers exposed to the Internet. Here, the groups to which one has been assigned and the rights to different system components play an essential role. In addition, it is common for users to share information and documents and work on them together. This type of information is of particular interest to us when planning our attacks. For example, if we compromise a user account assigned to a developer group, we may gain access to most of the resources used by company developers. This will likely provide us with crucial internal information about the systems and could help us to identify flaws or further our access. 2.8.5 (Privilege) Exploitation Once we have found and prioritized these paths, we can jump to the step where we use these to access the other systems. We often find ways to crack passwords and hashes and gain higher privileges. Another standard method is to use our existing credentials on other systems. There will also be situations where we do not even have to crack the hashes but can use them directly. For example, we can use the tool Responder to intercept NTLMv2 hashes. If we can intercept a hash from an administrator, then we can use the pass-the-hash technique to log in as that administrator (in most cases) on multiple hosts and servers. After all, the Lateral Movement stage aims to move through the internal network. Existing data and information can be versatile and often used in many ways. 2.8.6 Post-Exploitation Once we have reached one or more hosts or servers, we go through the steps of the post-exploitation stage again for each system. Here we again collect system information, data from created users, and business information that can be presented as evidence. However, we must again consider how this different information must be handled and the rules defined around sensitive data in the contract. Finally, we are ready to move on to the Proof-of-Concept phase to show off our hard work and help our client, and those responsible for remediation efficiently reproduce our results. 2.9 Proof-of-Concept Proof of Concept (PoC) or Proof of Principle is a project management term. In project management, it serves as proof that a project is feasible in principle. The criteria for this can lie in technical or business factors. Therefore, it is the basis for further work, in our case, the necessary steps to secure the corporate network by confirming the discovered vulnerabilities. In other words, it serves as a decision-making basis for the further course of action. At the same time, it enables risks to be identified and minimized. This project step is often integrated into the development process for new application software (prototyping) or IT security solutions. For us in information security, this is where we prove vulnerabilities in operating systems or application software. We use this PoC to prove that a security problem exists so that the developers or administrators can validate it, reproduce it, see the impact, and test their remediation efforts. One of the most common examples used to prove software vulnerabilities is executing the calculator (calc.exe on Windows) on the target system. In principle, the PoC also assesses the probability of success of system access from actual exploitation. A PoC can have many different representations. For example, documentation of the vulnerabilities found can also constitute a PoC. The more practical version of a PoC is a script or code that automatically exploits the vulnerabilities found. This demonstrates the flawless exploitation of the vulnerabilities. This variant is straightforward for an administrator or developer because they can see what steps our script takes to exploit the vulnerability. However, there is one significant disadvantage that has occurred from time to time. Once the administrators and developers have received such a script from us, it is easy for them to “fight” against our script. They focus on changing the systems so that the script we created no longer works. The important thing is that the script is only one way of exploiting a given vulnerability. Therefore, working against our script instead of with it and modifying and securing the systems so that our script no longer works does not mean that the information obtained from the script cannot be obtained in another way. It is an important aspect that should be discussed with the administrators and developers and explicitly mentioned and pointed out. The report they receive from us should help them see the entire picture, focus on the broader issues, and provide clear remediation advice. Including an attack chain walkthrough in the event of domain compromise during an internal is a great way to show how multiple flaws can be combined and how fixing one flaw will break the chain, but the other flaws will still exist. If these are not also fixed, there may be another path to get to the point where the attack chain was remediated and continue onwards. We should also drive this point home during our report review meeting. For example, if a user uses the password Password123, the underlying vulnerability is not the password but the password policy. If a Domain Admin is found to be using that password and it is changed, that one account will now have a stronger password, but the problem of weak passwords will likely still be endemic within the organization. If the password policy followed high standards, the user would not be able to use such a weak password. Administrators and developers are responsible for the functionality and the quality of their systems and applications. Furthermore, high quality stands for high standards, which we should emphasize through our remediation recommendations. 2.10 Post-Engagement Much like there is considerable legwork before an engagement officially starts (when testing begins), we must perform many activities (many of them contractually binding) after our scans, exploitation, lateral movement, and post-exploitation activities are complete. No two engagements are the same, so these activities may differ slightly but generally must be performed to close out an engagement fully. 2.10.1 Cleanup Once testing is complete, we should perform any necessary cleanup, such as deleting tools/scripts uploaded to target systems, reverting any (minor) configuration changes we may have made, etc. We should have detailed notes of all of our activities, making any cleanup activities easy and efficient. If we cannot access a system where an artifact needs to be deleted, or another change reverted, we should alert the client and list these issues in the report appendices. Even if we can remove any uploaded files and revert changes (such as adding a local admin account), we should document these changes in our report appendices in case the client receives alerts that they need to follow up on and confirm that the activity in question was part of our sanctioned testing. 2.10.2 Documentation and Reporting Before completing the assessment and disconnecting from the client’s internal network or sending “stop” notification emails to signal the end of testing (meaning no more interaction with the client’s hosts), we must make sure to have adequate documentation for all findings that we plan to include in our report. This includes command output, screenshots, a listing of affected hosts, and anything else specific to the client environment or finding. We should also make sure that we have retrieved all scan and log output if the client hosted a VM in their infrastructure for an internal penetration test and any other data that may be included as part of the report or as supplementary documentation. We should not keep any Personal Identifiable Information (PII), potentially incriminating info, or other sensitive data we came across throughout testing. We should already have a detailed list of the findings we will include in the report and all necessary details to tailor the findings to the client’s environment. Our report deliverable (which is covered in detail in the Documentation &amp; Reporting module) should consist of the following: An attack chain (in the event of full internal compromise or external to internal access) detailing steps taken to achieve compromise A strong executive summary that a non-technical audience can understand Detailed findings specific to the client’s environment that include a risk rating, finding impact, remediation recommendations, and high-quality external references related to the issue Adequate steps to reproduce each finding so the team responsible for remediation can understand and test the issue while putting fixes in place Near, medium, and long-term recommendations specific to the environment Appendices which include information such as the target scope, OSINT data (if relevant to the engagement), password cracking analysis (if relevant), discovered ports/services, compromised hosts, compromised accounts, files transferred to client-owned systems, any account creation/system modifications, an Active Directory security analysis (if relevant), relevant scan data/supplementary documentation, and any other information necessary to explain a specific finding or recommendation further At this stage, we will create a draft report that is the first deliverable our client will receive. From here, they will be able to comment on the report and ask for any necessary clarification/modifications. 2.10.3 Report Review Meeting Once the draft report is delivered, and the client has had a chance to distribute it internally and review it in-depth, it is customary to hold a report review meeting to walk through the assessment results. The report review meeting typically includes the same folks from the client and the firm performing the assessment. Depending on the types of findings, the client may bring in additional technical subject matter experts if the finding is related to a system or application they are responsible for. Typically we will not read the entire report word for word but walk through each finding briefly and give an explanation from our own perspective/experience. The client will have the opportunity to ask questions about anything in the report, ask for clarifications, or point out issues that need to be corrected. Often the client will come with a list of questions about specific findings and will not want to cover every finding in detail (such as low-risk ones). 2.10.4 Deliverable Acceptance The Scope of Work should clearly define the acceptance of any project deliverables. In penetration test assessments, generally, we deliver a report marked DRAFT and give the client a chance to review and comment. Once the client has submitted feedback (i.e., management responses, requests for clarification/changes, additional evidence, etc.) either by email or (ideally) during a report review meeting, we can issue them a new version of the report marked FINAL. Some audit firms that clients may be beholden to will not accept a penetration test report with a DRAFT designation. Other companies will not care, but keeping a uniform approach across all customers is best. 2.10.5 Post-Remediation Testing Most engagements include post-remediation testing as part of the project’s total cost. In this phase, we will review any documentation provided by the client showing evidence of remediation or just a list of remediated findings. We will need to reaccess the target environment and test each issue to ensure it was appropriately remediated. We will issue a post-remediation report that clearly shows the state of the environment before and after post-remediation testing. For example, we may include a table such as: # Finding Severity Finding Title Status 1 High SQL Injection Remediated 2 High Broken Authentication Remediated 3 High Unrestricted File Upload Remediated 4 High Inadequate Web and Egress Filtering Not Remediated 5 Medium SMB Signing Not Enabled Not Remediated 6 Low Directory Listing Enabled Not Remediated For each finding (where possible), we will want to show evidence that the issue is no longer present in the environment through scan output or proof that the original exploitation techniques fail. 2.10.6 Role of the Pentester in Remediation Since a penetration test is essentially an audit, we must remain impartial third parties and not perform remediation on our findings (such as fixing code, patching systems, or making configuration changes in Active Directory). We must maintain a degree of independence and can serve as trusted advisors by giving general remediation advice on how a specific issue could be fixed or be available to explain further/demonstrate a finding so the team assigned to remediate it has a better understanding. We should not be implementing changes ourselves or even giving precise remediation advice (i.e., for SQL Injection, we may say “sanitize user input” but not give the client a rewritten piece of code). This will help maintain the assessment’s integrity and not introduce any potential conflict of interest into the process. 2.10.7 Data Retention After a penetration test concludes, we will have a considerable amount of client-specific data such as scan results, log output, credentials, screenshots, and more. Data retention and destruction requirements may differ from country to country and firm to firm, and procedures surrounding each should be outlined clearly in the contract language of the Scope of Work and the Rules of Engagement. Per Penetration Testing Guidance from the PCI Data Security Standard (PCI DSS): “While there are currently no PCI DSS requirements regarding the retention of evidence collected by the penetration tester, it is a recommended best practice that the tester retain such evidence (whether internal to the organization or a third-party provider) for a period of time while considering any local, regional, or company laws that must be followed for the retention of evidence. This evidence should be available upon request from the target entity or other authorized entities as defined in the rules of engagement.” We should retain evidence for some time after the penetration test in case questions arise about specific findings or to assist with retesting “closed” findings after the client has performed remediation activities. Any data retained after the assessment should be stored in a secure location owned and controlled by the firm and encrypted at rest. All data should be wiped from tester systems at the conclusion of an assessment. A new virtual machine specific to the client in question should be created for any post-remediation testing or investigation of findings related to client inquiries. 2.10.8 Close Out Once we have delivered the final report, assisted the client with questions regarding remediation, and performed post-remediation testing/issued a new report, we can finally close the project. At this stage, we should ensure that any systems used to connect to the client’s systems or process data have been wiped or destroyed and that any artifacts leftover from the engagement are stored securely (encrypted) per our firm’s policy and per contractual obligations to our client. The final steps would be invoicing the client and collecting payment for services rendered. Finally, it is always good to follow up with a post-assessment client satisfaction survey so the team and management, in particular, can see what went well during the engagement and what could be improved upon from a company process standpoint and the individual consultant assigned to the project. Discussions for follow-on work may arise in the weeks or months after if the client was pleased with our work and day-to-day interactions. As we continually grow our technical skillset, we should always look for ways to improve our soft skills and become more well-rounded professional consultants. In the end, the client will usually remember interactions during the assessment, communication, and how they were treated/valued by the firm they engage, not the fancy exploit chain the pentester pulled off to pwn their systems. Take this time to self-reflect and work on continuous improvement in all aspects of your role as a professional penetration tester. "],["network-enumeration.html", "3 Network Enumeration 3.1 Enumeration 3.2 Introduction to Nmap 3.3 Host Discovery 3.4 Host and Port Scanning 3.5 Saving the Results 3.6 Service Enumeration 3.7 Nmap Scription Engine 3.8 Performance 3.9 Firewall and IDS-IPS Evasion", " 3 Network Enumeration 3.1 Enumeration Enumeration is the most critical part of all. The art, the difficulty, and the goal are not to gain access to our target computer. Instead, it is identifying all of the ways we could attack a target we must find. It is not just based on the tools we use. They will only do much good if we know what to do with the information we get from them. The tools are just tools, and tools alone should never replace our knowledge and our attention to detail. Here it is much more about actively interacting with the individual services to see what information they provide us and what possibilities they offer us. It is essential to understand how these services work and what syntax they use for effective communication and interaction with the different services. This phase aims to improve our knowledge and understanding of the technologies, protocols, and how they work and learn to deal with new information and adapt to our already acquired knowledge. Enumeration is collecting as much information as possible. The more information we have, the easier it will be for us to find vectors of attack. Imagine the following situation: Our partner is not at home and has misplaced our car keys. We call our partner and ask where the keys are. If we get an answer like “in the living room,” it is entirely unclear and can take much time to find them there. However, what if our partner tells us something like “in the living room on the white shelf, next to the TV, in the third drawer”? As a result, it will be much easier to find them. It’s not hard to get access to the target system once we know how to do it. Most of the ways we can get access we can narrow down to the following two points: Functions and/or resources that allow us to interact with the target and/or provide additional information. Information that provides us with even more important information to access our target. When scanning and inspecting, we look exactly for these two possibilities. Most of the information we get comes from misconfigurations or neglect of security for the respective services. Misconfigurations are either the result of ignorance or a wrong security mindset. For example, if the administrator only relies on the firewall, Group Policy Objects (GPOs), and continuous updates, it is often not enough to secure the network. Enumeration is the key. That’s what most people say, and they are right. However, it is too often misunderstood. Most people understand that they haven’t tried all the tools to get the information they need. Most of the time, however, it’s not the tools we haven’t tried, but rather the fact that we don’t know how to interact with the service and what’s relevant. That’s precisely the reason why so many people stay stuck in one spot and don’t get ahead. Had these people invested a couple of hours learning more about the service, how it works, and what it is meant for, they would save a few hours or even days from reaching their goal and get access to the system. Manual enumeration is a critical component. Many scanning tools simplify and accelerate the process. However, these cannot always bypass the security measures of the services. The easiest way to illustrate this is to use the following example: Most scanning tools have a timeout set until they receive a response from the service. If this tool does not respond within a specific time, this service/port will be marked as closed, filtered, or unknown. In the last two cases, we will still be able to work with it. However, if a port is marked as closed and Nmap doesn’t show it to us, we will be in a bad situation. This service/port may provide us with the opportunity to find a way to access the system. Therefore, this result can take much unnecessary time until we find it. 3.2 Introduction to Nmap Network Mapper (Nmap) is an open-source network analysis and security auditing tool written in C, C++, Python, and Lua. It is designed to scan networks and identify which hosts are available on the network using raw packets, and services and applications, including the name and version, where possible. It can also identify the operating systems and versions of these hosts. Besides other features, Nmap also offers scanning capabilities that can determine if packet filters, firewalls, or intrusion detection systems (IDS) are configured as needed. 3.2.1 Use Cases The tool is one of the most used tools by network administrators and IT security specialists. It is used to: Audit the security aspects of networks Simulate penetration tests Check firewall and IDS settings and configurations Types of possible connections Network mapping Response analysis Identify open ports Vulnerability assessment as well. 3.2.2 Nmap Architecture Nmap offers many different types of scans that can be used to obtain various results about our targets. Basically, Nmap can be divided into the following scanning techniques: Host discovery Port scanning Service enumeration and detection OS detection Scriptable interaction with the target service (Nmap Scripting Engine) 3.2.3 Syntax The syntax for Nmap is fairly simple and looks like this: notluken@htb[/htb]$ nmap &lt;scan types&gt; &lt;options&gt; &lt;target&gt; 3.2.4 Scan Techniques Nmap offers many different scanning techniques, making different types of connections and using differently structured packets to send. Here we can see all the scanning techniques Nmap offers: notluken@htb[/htb]$ nmap --help &lt;SNIP&gt; SCAN TECHNIQUES: -sS/sT/sA/sW/sM: TCP SYN/Connect()/ACK/Window/Maimon scans -sU: UDP Scan -sN/sF/sX: TCP Null, FIN, and Xmas scans --scanflags &lt;flags&gt;: Customize TCP scan flags -sI &lt;zombie host[:probeport]&gt;: Idle scan -sY/sZ: SCTP INIT/COOKIE-ECHO scans -sO: IP protocol scan -b &lt;FTP relay host&gt;: FTP bounce scan &lt;SNIP&gt; For example, the TCP-SYN scan (-sS) is one of the default settings unless we have defined otherwise and is also one of the most popular scan methods. This scan method makes it possible to scan several thousand ports per second. The TCP-SYN scan sends one packet with the SYN flag and, therefore, never completes the three-way handshake, which results in not establishing a full TCP connection to the scanned port. If our target sends a SYN-ACK flagged packet back to us, Nmap detects that the port is open. If the target responds with an RST flagged packet, it is an indicator that the port is closed. If Nmap does not receive a packet back, it will display it as filtered. Depending on the firewall configuration, certain packets may be dropped or ignored by the firewall. Let us take an example of such a scan. notluken@htb[/htb]$ sudo nmap -sS localhost Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-11 22:50 UTC Nmap scan report for localhost (127.0.0.1) Host is up (0.000010s latency). Not shown: 996 closed ports PORT STATE SERVICE 22/tcp open ssh 80/tcp open http 5432/tcp open postgresql 5901/tcp open vnc-1 Nmap done: 1 IP address (1 host up) scanned in 0.18 seconds In this example, we can see that we have four different TCP ports open. In the first column, we see the number of the port. Then, in the second column, we see the service’s status and then what kind of service it is. 3.3 Host Discovery When we need to conduct an internal penetration test for the entire network of a company, for example, then we should, first of all, get an overview of which systems are online that we can work with. To actively discover such systems on the network, we can use various Nmap host discovery options. There are many options Nmap provides to determine whether our target is alive or not. The most effective host discovery method is to use ICMP echo requests, which we will look into. It is always recommended to store every single scan. This can later be used for comparison, documentation, and reporting. After all, different tools may produce different results. Therefore it can be beneficial to distinguish which tool produces which results. 3.3.1 Scan Network Range notluken@htb[/htb]$ sudo nmap 10.129.2.0/24 -sn -oA tnet | grep for | cut -d&quot; &quot; -f5 10.129.2.4 10.129.2.10 10.129.2.11 10.129.2.18 10.129.2.19 10.129.2.20 10.129.2.28 Scanning Options Description 10.129.2.0/24 Target network range. -sn Disables port scanning. -oA tnet Stores the results in all formats starting with the name ‘tnet’. This scanning method works only if the firewalls of the hosts allow it. Otherwise, we can use other scanning techniques to find out if the hosts are active or not. We will take a closer look at these techniques in “Firewall and IDS Evasion”. 3.3.2 Scan IP List During an internal penetration test, it is not uncommon for us to be provided with an IP list with the hosts we need to test. Nmap also gives us the option of working with lists and reading the hosts from this list instead of manually defining or typing them in. Such a list could look something like this: notluken@htb[/htb]$ cat hosts.lst 10.129.2.4 10.129.2.10 10.129.2.11 10.129.2.18 10.129.2.19 10.129.2.20 10.129.2.28 If we use the same scanning technique on the predefined list, the command will look like this: notluken@htb[/htb]$ sudo nmap -sn -oA tnet -iL hosts.lst | grep for | cut -d&quot; &quot; -f5 10.129.2.18 10.129.2.19 10.129.2.20 Scanning Options Description -sn Disables port scanning. -oA tnet Stores the results in all formats starting with the name ‘tnet’. -iL Performs defined scans against targets in provided ‘hosts.lst’ list. In this example, we see that only 3 of 7 hosts are active. Remember, this may mean that the other hosts ignore the default ICMP echo requests because of their firewall configurations. Since Nmap does not receive a response, it marks those hosts as inactive. 3.3.3 Scan Multiple IPs It can also happen that we only need to scan a small part of a network. An alternative to the method we used last time is to specify multiple IP addresses. notluken@htb[/htb]$ sudo nmap -sn -oA tnet 10.129.2.18 10.129.2.19 10.129.2.20| grep for | cut -d&quot; &quot; -f5 10.129.2.18 10.129.2.19 10.129.2.20 If these IP addresses are next to each other, we can also define the range in the respective octet. notluken@htb[/htb]$ sudo nmap -sn -oA tnet 10.129.2.18-20| grep for | cut -d&quot; &quot; -f5 10.129.2.18 10.129.2.19 10.129.2.20 3.3.4 Scan Single IP Before we scan a single host for open ports and its services, we first have to determine if it is alive or not. For this, we can use the same method as before. notluken@htb[/htb]$ sudo nmap 10.129.2.18 -sn -oA host Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-14 23:59 CEST Nmap scan report for 10.129.2.18 Host is up (0.087s latency). MAC Address: DE:AD:00:00:BE:EF Nmap done: 1 IP address (1 host up) scanned in 0.11 seconds Scanning Options Description 10.129.2.18 Performs defined scans against the target. -sn Disables port scanning. -oA host Stores the results in all formats starting with the name ‘host’. If we disable port scan (-sn), Nmap automatically ping scan with ICMP Echo Requests (-PE). Once such a request is sent, we usually expect an ICMP reply if the pinging host is alive. The more interesting fact is that our previous scans did not do that because before Nmap could send an ICMP echo request, it would send an ARP ping resulting in an ARP reply. We can confirm this with the “--packet-trace” option. To ensure that ICMP echo requests are sent, we also define the option (-PE) for this. notluken@htb[/htb]$ sudo nmap 10.129.2.18 -sn -oA host -PE --packet-trace Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-15 00:08 CEST SENT (0.0074s) ARP who-has 10.129.2.18 tell 10.10.14.2 RCVD (0.0309s) ARP reply 10.129.2.18 is-at DE:AD:00:00:BE:EF Nmap scan report for 10.129.2.18 Host is up (0.023s latency). MAC Address: DE:AD:00:00:BE:EF Nmap done: 1 IP address (1 host up) scanned in 0.05 seconds Scanning Options Description 10.129.2.18 Performs defined scans against the target. -sn Disables port scanning. -oA host Stores the results in all formats starting with the name ‘host’. -PE Performs the ping scan by using ‘ICMP Echo requests’ against the target. --packet-trace Shows all packets sent and received Another way to determine why Nmap has our target marked as “alive” is with the “--reason” option. notluken@htb[/htb]$ sudo nmap 10.129.2.18 -sn -oA host -PE --reason Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-15 00:10 CEST SENT (0.0074s) ARP who-has 10.129.2.18 tell 10.10.14.2 RCVD (0.0309s) ARP reply 10.129.2.18 is-at DE:AD:00:00:BE:EF Nmap scan report for 10.129.2.18 Host is up, received arp-response (0.028s latency). MAC Address: DE:AD:00:00:BE:EF Nmap done: 1 IP address (1 host up) scanned in 0.03 seconds Scanning Options Description 10.129.2.18 Performs defined scans against the target. -sn Disables port scanning. -oA host Stores the results in all formats starting with the name ‘host’. -PE Performs the ping scan by using ‘ICMP Echo requests’ against the target. --reason Displays the reason for specific result. We see here that Nmap does indeed detect whether the host is alive or not through the ARP request and ARP reply alone. To disable ARP requests and scan our target with the desired ICMP echo requests, we can disable ARP pings by setting the “--disable-arp-ping” option. Then we can scan our target again and look at the packets sent and received. notluken@htb[/htb]$ sudo nmap 10.129.2.18 -sn -oA host -PE --packet-trace --disable-arp-ping Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-15 00:12 CEST SENT (0.0107s) ICMP [10.10.14.2 &gt; 10.129.2.18 Echo request (type=8/code=0) id=13607 seq=0] IP [ttl=255 id=23541 iplen=28 ] RCVD (0.0152s) ICMP [10.129.2.18 &gt; 10.10.14.2 Echo reply (type=0/code=0) id=13607 seq=0] IP [ttl=128 id=40622 iplen=28 ] Nmap scan report for 10.129.2.18 Host is up (0.086s latency). MAC Address: DE:AD:00:00:BE:EF Nmap done: 1 IP address (1 host up) scanned in 0.11 seconds We have already mentioned in the “Learning Process,” and at the beginning of this module, it is essential to pay attention to details. An ICMP echo request can help us determine if our target is alive and identify its system. More strategies about host discovery can be found at: https://nmap.org/book/host-discovery-strategies.html 3.4 Host and Port Scanning It is essential to understand how the tool we use works and how it performs and processes the different functions. We will only understand the results if we know what they mean and how they are obtained. Therefore we will take a closer look at and analyze some of the scanning methods. After we have found out that our target is alive, we want to get a more accurate picture of the system. The information we need includes: Open ports and its services Service versions Information that the services provided Operating system There are a total of 6 different states for a scanned port we can obtain: State Description open This indicates that the connection to the scanned port has been established. These connections can be TCP connections, UDP datagrams as well as SCTP associations. closed When the port is shown as closed, the TCP protocol indicates that the packet we received back contains an RST flag. This scanning method can also be used to determine if our target is alive or not. filtered Nmap cannot correctly identify whether the scanned port is open or closed because either no response is returned from the target for the port or we get an error code from the target. unfiltered This state of a port only occurs during the TCP-ACK scan and means that the port is accessible, but it cannot be determined whether it is open or closed. open\\|filtered If we do not get a response for a specific port, Nmap will set it to that state. This indicates that a firewall or packet filter may protect the port. closed\\|filtered This state only occurs in the IP ID idle scans and indicates that it was impossible to determine if the scanned port is closed or filtered by a firewall. 3.4.1 Discovering Open TCP Ports By default, Nmap scans the top 1000 TCP ports with the SYN scan (-sS). This SYN scan is set only to default when we run it as root because of the socket permissions required to create raw TCP packets. Otherwise, the TCP scan (-sT) is performed by default. This means that if we do not define ports and scanning methods, these parameters are set automatically. We can define the ports one by one (-p 22,25,80,139,445), by range (-p 22-445), by top ports (--top-ports=10) from the Nmap database that have been signed as most frequent, by scanning all ports (-p-) but also by defining a fast port scan, which contains top 100 ports (-F). 3.4.1.1 Scanning Top 10 TCP Ports notluken@htb[/htb]$ sudo nmap 10.129.2.28 --top-ports=10 Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-15 15:36 CEST Nmap scan report for 10.129.2.28 Host is up (0.021s latency). PORT STATE SERVICE 21/tcp closed ftp 22/tcp open ssh 23/tcp closed telnet 25/tcp open smtp 80/tcp open http 110/tcp open pop3 139/tcp filtered netbios-ssn 443/tcp closed https 445/tcp filtered microsoft-ds 3389/tcp closed ms-wbt-server MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) Nmap done: 1 IP address (1 host up) scanned in 1.44 seconds Scanning Options Description 10.129.2.28 Scans the specified target. --top-ports=10 Scans the specified top ports that have been defined as most frequent. We see that we only scanned the top 10 TCP ports of our target, and Nmap displays their state accordingly. If we trace the packets Nmapsends, we will see the RST flag on TCP port 21 that our target sends back to us. To have a clear view of the SYN scan, we disable the ICMP echo requests (-Pn), DNS resolution (-n), and ARP ping scan (--disable-arp-ping). 3.4.1.2 Nmap - Trace the Packets Host and Port Scanning notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p 21 --packet-trace -Pn -n --disable-arp-ping Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-15 15:39 CEST SENT (0.0429s) TCP 10.10.14.2:63090 &gt; 10.129.2.28:21 S ttl=56 id=57322 iplen=44 seq=1699105818 win=1024 &lt;mss 1460&gt; RCVD (0.0573s) TCP 10.129.2.28:21 &gt; 10.10.14.2:63090 RA ttl=64 id=0 iplen=40 seq=0 win=0 Nmap scan report for 10.11.1.28 Host is up (0.014s latency). PORT STATE SERVICE 21/tcp closed ftp MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) Nmap done: 1 IP address (1 host up) scanned in 0.07 seconds Scanning Options Description 10.129.2.28 Scans the specified target. -p 21 Scans only the specified port. --packet-trace Shows all packets sent and received. -n Disables DNS resolution. --disable-arp-ping Disables ARP ping. We can see from the SENT line that we (10.10.14.2) sent a TCP packet with the SYN flag (S) to our target (10.129.2.28). In the next RCVD line, we can see that the target responds with a TCP packet containing the RST and ACK flags (RA). RST and ACK flags are used to acknowledge receipt of the TCP packet (ACK) and to end the TCP session (RST). 3.4.1.3 Request Message Description SENT (0.0429s) Indicates the SENT operation of Nmap, which sends a packet to the target. TCP Shows the protocol that is being used to interact with the target port. 10.10.14.2:63090 &gt; Represents our IPv4 address and the source port, which will be used by Nmap to send the packets. 10.129.2.28:21 Shows the target IPv4 address and the target port. S SYN flag of the sent TCP packet. ttl=56 id=57322 iplen=44 seq=1699105818 win=1024 mss 1460 Additional TCP Header parameters. 3.4.1.4 Response Message Description RCVD (0.0573s) Indicates a received packet from the target. TCP Shows the protocol that is being used. 10.129.2.28:21 &gt; Represents targets IPv4 address and the source port, which will be used to reply. 10.10.14.2:63090 Shows our IPv4 address and the port that will be replied to. RA RST and ACK flags of the sent TCP packet. ttl=64 id=0 iplen=40 seq=0 win=0 Additional TCP Header parameters. 3.4.1.5 Connect Scan The Nmap TCP Connect Scan (-sT) uses the TCP three-way handshake to determine if a specific port on a target host is open or closed. The scan sends an SYN packet to the target port and waits for a response. It is considered open if the target port responds with an SYN-ACK packet and closed if it responds with an RST packet. The Connect scan (also known as a full TCP connect scan) is highly accurate because it completes the three-way TCP handshake, allowing us to determine the exact state of a port (open, closed, or filtered). However, it is not the most stealthy. In fact, the Connect scan is one of the least stealthy techniques, as it fully establishes a connection, which creates logs on most systems and is easily detected by modern IDS/IPS solutions. That said, the Connect scan can still be useful in certain situations, particularly when accuracy is a priority, and the goal is to map the network without causing significant disruption to services. Since the scan fully establishes a TCP connection, it interacts cleanly with services, making it less likely to cause service errors or instability compared to more intrusive scans. While it is not the most stealthy method, it is sometimes considered a more “polite” scan because it behaves like a normal client connection, thus having minimal impact on the target services. It is also useful when the target host has a personal firewall that drops incoming packets but allows outgoing packets. In this case, a Connect scan can bypass the firewall and accurately determine the state of the target ports. However, it is important to note that the Connect scan is slower than other types of scans because it requires the scanner to wait for a response from the target after each packet it sends, which could take some time if the target is busy or unresponsive. Scans like the SYN scan (also known as a half-open scan) are generally considered more stealthy because they do not complete the full handshake, leaving the connection incomplete after sending the initial SYN packet. This minimizes the chance of triggering connection logs while still gathering port state information. Advanced IDS/IPS systems, however, have adapted to detect even these subtler techniques. 3.4.1.6 Connect Scan on TCP Port 443 notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p 443 --packet-trace --disable-arp-ping -Pn -n --reason -sT Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-15 16:26 CET CONN (0.0385s) TCP localhost &gt; 10.129.2.28:443 =&gt; Operation now in progress CONN (0.0396s) TCP localhost &gt; 10.129.2.28:443 =&gt; Connected Nmap scan report for 10.129.2.28 Host is up, received user-set (0.013s latency). PORT STATE SERVICE REASON 443/tcp open https syn-ack Nmap done: 1 IP address (1 host up) scanned in 0.04 seconds 3.4.2 Filtered Ports When a port is shown as filtered, it can have several reasons. In most cases, firewalls have certain rules set to handle specific connections. The packets can either be dropped, or rejected. When a packet gets dropped, Nmap receives no response from our target, and by default, the retry rate (--max-retries) is set to 10. This means Nmap will resend the request to the target port to determine if the previous packet was accidentally mishandled or not. Let us look at an example where the firewall drops the TCP packets we send for the port scan. Therefore we scan the TCP port 139, which was already shown as filtered. To be able to track how our sent packets are handled, we deactivate the ICMP echo requests (-Pn), DNS resolution (-n), and ARP ping scan (--disable-arp-ping) again. Host and Port Scanning notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p 139 --packet-trace -n --disable-arp-ping -Pn # Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-15 15:45 CEST SENT (0.0381s) TCP 10.10.14.2:60277 &gt; 10.129.2.28:139 S ttl=47 id=14523 iplen=44 seq=4175236769 win=1024 &lt;mss 1460&gt; SENT (1.0411s) TCP 10.10.14.2:60278 &gt; 10.129.2.28:139 S ttl=45 id=7372 iplen=44 seq=4175171232 win=1024 &lt;mss 1460&gt; Nmap scan report for 10.129.2.28 Host is up. # PORT STATE SERVICE 139/tcp filtered netbios-ssn MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) # Nmap done: 1 IP address (1 host up) scanned in 2.06 seconds Scanning Options Description 10.129.2.28 Scans the specified target. -p 139 Scans only the specified port. --packet-trace Shows all packets sent and received. -n Disables DNS resolution. --disable-arp-ping Disables ARP ping. -Pn Disables ICMP Echo requests. We see in the last scan that Nmap sent two TCP packets with the SYN flag. By the duration (2.06s) of the scan, we can recognize that it took much longer than the previous ones (~0.05s). The case is different if the firewall rejects the packets. For this, we look at TCP port 445, which is handled accordingly by such a rule of the firewall. Host and Port Scanning notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p 445 --packet-trace -n --disable-arp-ping -Pn # Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-15 15:55 CEST SENT (0.0388s) TCP 10.129.2.28:52472 &gt; 10.129.2.28:445 S ttl=49 id=21763 iplen=44 seq=1418633433 win=1024 &lt;mss 1460&gt; RCVD (0.0487s) ICMP [10.129.2.28 &gt; 10.129.2.28 Port 445 unreachable (type=3/code=3) ] IP [ttl=64 id=20998 iplen=72 ] Nmap scan report for 10.129.2.28 Host is up (0.0099s latency). # PORT STATE SERVICE 445/tcp filtered microsoft-ds MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) # Nmap done: 1 IP address (1 host up) scanned in 0.05 seconds Scanning Options Description 10.129.2.28 Scans the specified target. -p 445 Scans only the specified port. --packet-trace Shows all packets sent and received. -n Disables DNS resolution. --disable-arp-ping Disables ARP ping. -Pn Disables ICMP Echo requests. As a response, we receive an ICMP reply with type 3 and error code 3, which indicates that the desired port is unreachable. Nevertheless, if we know that the host is alive, we can strongly assume that the firewall on this port is rejecting the packets, and we will have to take a closer look at this port later. 3.4.3 Discovering Open UDP Ports Some system administrators sometimes forget to filter the UDP ports in addition to the TCP ones. Since UDP is a stateless protocoland does not require a three-way handshake like TCP. We do not receive any acknowledgment. Consequently, the timeout is much longer, making the whole UDP scan (-sU) much slower than the TCP scan (-sS). Let’s look at an example of what a UDP scan (-sU) can look like and what results it gives us. 3.4.3.1 UDP Port Scan Host and Port Scanning notluken@htb[/htb]$ sudo nmap 10.129.2.28 -F -sU # Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-15 16:01 CEST Nmap scan report for 10.129.2.28 Host is up (0.059s latency). Not shown: 95 closed ports PORT STATE SERVICE 68/udp open|filtered dhcpc 137/udp open netbios-ns 138/udp open|filtered netbios-dgm 631/udp open|filtered ipp 5353/udp open zeroconf MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) # Nmap done: 1 IP address (1 host up) scanned in 98.07 seconds Scanning Options Description 10.129.2.28 Scans the specified target. -F Scans top 100 ports. -sU Performs a UDP scan. Another disadvantage of this is that we often do not get a response back because Nmap sends empty datagrams to the scanned UDP ports, and we do not receive any response. So we cannot determine if the UDP packet has arrived at all or not. If the UDP port is open, we only get a response if the application is configured to do so. Host and Port Scanning notluken@htb[/htb]$ sudo nmap 10.129.2.28 -sU -Pn -n --disable-arp-ping --packet-trace -p 137 --reason # Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-15 16:15 CEST SENT (0.0367s) UDP 10.10.14.2:55478 &gt; 10.129.2.28:137 ttl=57 id=9122 iplen=78 RCVD (0.0398s) UDP 10.129.2.28:137 &gt; 10.10.14.2:55478 ttl=64 id=13222 iplen=257 Nmap scan report for 10.129.2.28 Host is up, received user-set (0.0031s latency). # PORT STATE SERVICE REASON 137/udp open netbios-ns udp-response ttl 64 MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) # Nmap done: 1 IP address (1 host up) scanned in 0.04 seconds Scanning Options Description 10.129.2.28 Scans the specified target. -sU Performs a UDP scan. -Pn Disables ICMP Echo requests. -n Disables DNS resolution. --disable-arp-ping Disables ARP ping. --packet-trace Shows all packets sent and received. -p 137 Scans only the specified port. --reason Displays the reason a port is in a particular state. If we get an ICMP response with error code 3 (port unreachable), we know that the port is indeed closed. Host and Port Scanning notluken@htb[/htb]$ sudo nmap 10.129.2.28 -sU -Pn -n --disable-arp-ping --packet-trace -p 100 --reason # Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-15 16:25 CEST SENT (0.0445s) UDP 10.10.14.2:63825 &gt; 10.129.2.28:100 ttl=57 id=29925 iplen=28 RCVD (0.1498s) ICMP [10.129.2.28 &gt; 10.10.14.2 Port unreachable (type=3/code=3) ] IP [ttl=64 id=11903 iplen=56 ] Nmap scan report for 10.129.2.28 Host is up, received user-set (0.11s latency). # PORT STATE SERVICE REASON 100/udp closed unknown port-unreach ttl 64 MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) # Nmap done: 1 IP address (1 host up) scanned in 0.15 seconds Scanning Options Description 10.129.2.28 Scans the specified target. -sU Performs a UDP scan. -Pn Disables ICMP Echo requests. -n Disables DNS resolution. --disable-arp-ping Disables ARP ping. --packet-trace Shows all packets sent and received. -p 100 Scans only the specified port. --reason Displays the reason a port is in a particular state. For all other ICMP responses, the scanned ports are marked as (open|filtered). Host and Port Scanning notluken@htb[/htb]$ sudo nmap 10.129.2.28 -sU -Pn -n --disable-arp-ping --packet-trace -p 138 --reason # Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-15 16:32 CEST SENT (0.0380s) UDP 10.10.14.2:52341 &gt; 10.129.2.28:138 ttl=50 id=65159 iplen=28 SENT (1.0392s) UDP 10.10.14.2:52342 &gt; 10.129.2.28:138 ttl=40 id=24444 iplen=28 Nmap scan report for 10.129.2.28 Host is up, received user-set. # PORT STATE SERVICE REASON 138/udp open|filtered netbios-dgm no-response MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) # Nmap done: 1 IP address (1 host up) scanned in 2.06 seconds Scanning Options Description 10.129.2.28 Scans the specified target. -sU Performs a UDP scan. -Pn Disables ICMP Echo requests. -n Disables DNS resolution. --disable-arp-ping Disables ARP ping. --packet-trace Shows all packets sent and received. -p 138 Scans only the specified port. --reason Displays the reason a port is in a particular state. Another handy method for scanning ports is the -sV option which is used to get additional available information from the open ports. This method can identify versions, service names, and details about our target. 3.4.4 Version Scan Host and Port Scanning notluken@htb[/htb]$ sudo nmap 10.129.2.28 -Pn -n --disable-arp-ping --packet-trace -p 445 --reason -sV # Starting Nmap 7.80 ( https://nmap.org ) at 2022-11-04 11:10 GMT SENT (0.3426s) TCP 10.10.14.2:44641 &gt; 10.129.2.28:445 S ttl=55 id=43401 iplen=44 seq=3589068008 win=1024 &lt;mss 1460&gt; RCVD (0.3556s) TCP 10.129.2.28:445 &gt; 10.10.14.2:44641 SA ttl=63 id=0 iplen=44 seq=2881527699 win=29200 &lt;mss 1337&gt; NSOCK INFO [0.4980s] nsock_iod_new2(): nsock_iod_new (IOD #1) NSOCK INFO [0.4980s] nsock_connect_tcp(): TCP connection requested to 10.129.2.28:445 (IOD #1) EID 8 NSOCK INFO [0.5130s] nsock_trace_handler_callback(): Callback: CONNECT SUCCESS for EID 8 [10.129.2.28:445] Service scan sending probe NULL to 10.129.2.28:445 (tcp) NSOCK INFO [0.5130s] nsock_read(): Read request from IOD #1 [10.129.2.28:445] (timeout: 6000ms) EID 18 NSOCK INFO [6.5190s] nsock_trace_handler_callback(): Callback: READ TIMEOUT for EID 18 [10.129.2.28:445] Service scan sending probe SMBProgNeg to 10.129.2.28:445 (tcp) NSOCK INFO [6.5190s] nsock_write(): Write request for 168 bytes to IOD #1 EID 27 [10.129.2.28:445] NSOCK INFO [6.5190s] nsock_read(): Read request from IOD #1 [10.129.2.28:445] (timeout: 5000ms) EID 34 NSOCK INFO [6.5190s] nsock_trace_handler_callback(): Callback: WRITE SUCCESS for EID 27 [10.129.2.28:445] NSOCK INFO [6.5320s] nsock_trace_handler_callback(): Callback: READ SUCCESS for EID 34 [10.129.2.28:445] (135 bytes) Service scan match (Probe SMBProgNeg matched with SMBProgNeg line 13836): 10.129.2.28:445 is netbios-ssn. Version: |Samba smbd|3.X - 4.X|workgroup: WORKGROUP| NSOCK INFO [6.5320s] nsock_iod_delete(): nsock_iod_delete (IOD #1) Nmap scan report for 10.129.2.28 Host is up, received user-set (0.013s latency). # PORT STATE SERVICE REASON VERSION 445/tcp open netbios-ssn syn-ack ttl 63 Samba smbd 3.X - 4.X (workgroup: WORKGROUP) Service Info: Host: Ubuntu # Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . # Nmap done: 1 IP address (1 host up) scanned in 6.55 seconds Scanning Options Description 10.129.2.28 Scans the specified target. -Pn Disables ICMP Echo requests. -n Disables DNS resolution. --disable-arp-ping Disables ARP ping. --packet-trace Shows all packets sent and received. -p 445 Scans only the specified port. --reason Displays the reason a port is in a particular state. -sV Performs a service scan. More information about port scanning techniques we can find at: https://nmap.org/book/man-port-scanning-techniques.html 3.5 Saving the Results 3.5.1 Different Formats While we run various scans, we should always save the results. We can use these later to examine the differences between the different scanning methods we have used. Nmap can save the results in 3 different formats. Normal output (-oN) with the .nmap file extension Grepable output (-oG) with the .gnmap file extension XML output (-oX) with the .xml file extension We can also specify the option (-oA) to save the results in all formats. The command could look like this: Saving the Results notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p- -oA target # Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-16 12:14 CEST Nmap scan report for 10.129.2.28 Host is up (0.0091s latency). Not shown: 65525 closed ports PORT STATE SERVICE 22/tcp open ssh 25/tcp open smtp 80/tcp open http MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) # Nmap done: 1 IP address (1 host up) scanned in 10.22 seconds Scanning Options Description 10.129.2.28 Scans the specified target. -p- Scans all ports. -oA target Saves the results in all formats, starting the name of each file with ‘target’. If no full path is given, the results will be stored in the directory we are currently in. Next, we look at the different formats Nmap has created for us. Saving the Results notluken@htb[/htb]$ ls # target.gnmap target.xml target.nmap 3.5.1.1 Normal Output Saving the Results notluken@htb[/htb]$ cat target.nmap # Nmap 7.80 scan initiated Tue Jun 16 12:14:53 2020 as: nmap -p- -oA target 10.129.2.28 Nmap scan report for 10.129.2.28 Host is up (0.053s latency). Not shown: 4 closed ports PORT STATE SERVICE 22/tcp open ssh 25/tcp open smtp 80/tcp open http MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) # Nmap done at Tue Jun 16 12:15:03 2020 -- 1 IP address (1 host up) scanned in 10.22 seconds 3.5.1.2 Grepable Output Saving the Results notluken@htb[/htb]$ cat target.gnmap # Nmap 7.80 scan initiated Tue Jun 16 12:14:53 2020 as: nmap -p- -oA target 10.129.2.28 Host: 10.129.2.28 () Status: Up Host: 10.129.2.28 () Ports: 22/open/tcp//ssh///, 25/open/tcp//smtp///, 80/open/tcp//http/// Ignored State: closed (4) Nmap done at Tue Jun 16 12:14:53 2020 -- 1 IP address (1 host up) scanned in 10.22 seconds 3.5.1.3 XML Output Saving the Results notluken@htb[/htb]$ cat target.xml # &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE nmaprun&gt; &lt;?xml-stylesheet href=&quot;file:///usr/local/bin/../share/nmap/nmap.xsl&quot; type=&quot;text/xsl&quot;?&gt; &lt;!-- Nmap 7.80 scan initiated Tue Jun 16 12:14:53 2020 as: nmap -p- -oA target 10.129.2.28 --&gt; &lt;nmaprun scanner=&quot;nmap&quot; args=&quot;nmap -p- -oA target 10.129.2.28&quot; start=&quot;12145301719&quot; startstr=&quot;Tue Jun 16 12:15:03 2020&quot; version=&quot;7.80&quot; xmloutputversion=&quot;1.04&quot;&gt; &lt;scaninfo type=&quot;syn&quot; protocol=&quot;tcp&quot; numservices=&quot;65535&quot; services=&quot;1-65535&quot;/&gt; &lt;verbose level=&quot;0&quot;/&gt; &lt;debugging level=&quot;0&quot;/&gt; &lt;host starttime=&quot;12145301719&quot; endtime=&quot;12150323493&quot;&gt;&lt;status state=&quot;up&quot; reason=&quot;arp-response&quot; reason_ttl=&quot;0&quot;/&gt; &lt;address addr=&quot;10.129.2.28&quot; addrtype=&quot;ipv4&quot;/&gt; &lt;address addr=&quot;DE:AD:00:00:BE:EF&quot; addrtype=&quot;mac&quot; vendor=&quot;Intel Corporate&quot;/&gt; &lt;hostnames&gt; &lt;/hostnames&gt; &lt;ports&gt;&lt;extraports state=&quot;closed&quot; count=&quot;4&quot;&gt; &lt;extrareasons reason=&quot;resets&quot; count=&quot;4&quot;/&gt; &lt;/extraports&gt; &lt;port protocol=&quot;tcp&quot; portid=&quot;22&quot;&gt;&lt;state state=&quot;open&quot; reason=&quot;syn-ack&quot; reason_ttl=&quot;64&quot;/&gt;&lt;service name=&quot;ssh&quot; method=&quot;table&quot; conf=&quot;3&quot;/&gt;&lt;/port&gt; &lt;port protocol=&quot;tcp&quot; portid=&quot;25&quot;&gt;&lt;state state=&quot;open&quot; reason=&quot;syn-ack&quot; reason_ttl=&quot;64&quot;/&gt;&lt;service name=&quot;smtp&quot; method=&quot;table&quot; conf=&quot;3&quot;/&gt;&lt;/port&gt; &lt;port protocol=&quot;tcp&quot; portid=&quot;80&quot;&gt;&lt;state state=&quot;open&quot; reason=&quot;syn-ack&quot; reason_ttl=&quot;64&quot;/&gt;&lt;service name=&quot;http&quot; method=&quot;table&quot; conf=&quot;3&quot;/&gt;&lt;/port&gt; &lt;/ports&gt; &lt;times srtt=&quot;52614&quot; rttvar=&quot;75640&quot; to=&quot;355174&quot;/&gt; &lt;/host&gt; &lt;runstats&gt;&lt;finished time=&quot;12150323493&quot; timestr=&quot;Tue Jun 16 12:14:53 2020&quot; elapsed=&quot;10.22&quot; summary=&quot;Nmap done at Tue Jun 16 12:15:03 2020; 1 IP address (1 host up) scanned in 10.22 seconds&quot; exit=&quot;success&quot;/&gt;&lt;hosts up=&quot;1&quot; down=&quot;0&quot; total=&quot;1&quot;/&gt; &lt;/runstats&gt; &lt;/nmaprun&gt; 3.5.2 Style sheets With the XML output, we can easily create HTML reports that are easy to read, even for non-technical people. This is later very useful for documentation, as it presents our results in a detailed and clear way. To convert the stored results from XML format to HTML, we can use the tool xsltproc. Saving the Results notluken@htb[/htb]$ xsltproc target.xml -o target.html If we now open the HTML file in our browser, we see a clear and structured presentation of our results. 3.5.2.1 Nmap Report image More information about the output formats can be found at: https://nmap.org/book/output.html 3.6 Service Enumeration For us, it is essential to determine the application and its version as accurately as possible. We can use this information to scan for known vulnerabilities and analyze the source code for that version if we find it. An exact version number allows us to search for a more precise exploit that fits the service and the operating system of our target. 3.6.1 Service Version Detection It is recommended to perform a quick port scan first, which gives us a small overview of the available ports. This causes significantly less traffic, which is advantageous for us because otherwise we can be discovered and blocked by the security mechanisms. We can deal with these first and run a port scan in the background, which shows all open ports (-p-). We can use the version scan to scan the specific ports for services and their versions (-sV). A full port scan takes quite a long time. To view the scan status, we can press the [Space Bar] during the scan, which will cause Nmapto show us the scan status. Service Enumeration notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p- -sV # Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-15 19:44 CEST [Space Bar] Stats: 0:00:03 elapsed; 0 hosts completed (1 up), 1 undergoing SYN Stealth Scan SYN Stealth Scan Timing: About 3.64% done; ETC: 19:45 (0:00:53 remaining) Scanning Options Description 10.129.2.28 Scans the specified target. -p- Scans all ports. -sV Performs service version detection on specified ports. Another option (--stats-every=5s) that we can use is defining how periods of time the status should be shown. Here we can specify the number of seconds (s) or minutes (m), after which we want to get the status. Service Enumeration notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p- -sV --stats-every=5s # Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-15 19:46 CEST Stats: 0:00:05 elapsed; 0 hosts completed (1 up), 1 undergoing SYN Stealth Scan SYN Stealth Scan Timing: About 13.91% done; ETC: 19:49 (0:00:31 remaining) Stats: 0:00:10 elapsed; 0 hosts completed (1 up), 1 undergoing SYN Stealth Scan SYN Stealth Scan Timing: About 39.57% done; ETC: 19:48 (0:00:15 remaining) Scanning Options Description 10.129.2.28 Scans the specified target. -p- Scans all ports. -sV Performs service version detection on specified ports. --stats-every=5s Shows the progress of the scan every 5 seconds. We can also increase the verbosity level (-v / -vv), which will show us the open ports directly when Nmap detects them. Service Enumeration notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p- -sV -v # Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-15 20:03 CEST NSE: Loaded 45 scripts for scanning. Initiating ARP Ping Scan at 20:03 Scanning 10.129.2.28 [1 port] Completed ARP Ping Scan at 20:03, 0.03s elapsed (1 total hosts) Initiating Parallel DNS resolution of 1 host. at 20:03 Completed Parallel DNS resolution of 1 host. at 20:03, 0.02s elapsed Initiating SYN Stealth Scan at 20:03 Scanning 10.129.2.28 [65535 ports] Discovered open port 995/tcp on 10.129.2.28 Discovered open port 80/tcp on 10.129.2.28 Discovered open port 993/tcp on 10.129.2.28 Discovered open port 143/tcp on 10.129.2.28 Discovered open port 25/tcp on 10.129.2.28 Discovered open port 110/tcp on 10.129.2.28 Discovered open port 22/tcp on 10.129.2.28 &lt;SNIP&gt; Scanning Options Description 10.129.2.28 Scans the specified target. -p- Scans all ports. -sV Performs service version detection on specified ports. -v Increases the verbosity of the scan, which displays more detailed information. 3.6.2 Banner Grabbing Once the scan is complete, we will see all TCP ports with the corresponding service and their versions that are active on the system. Service Enumeration notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p- -sV # Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-15 20:00 CEST Nmap scan report for 10.129.2.28 Host is up (0.013s latency). Not shown: 65525 closed ports PORT STATE SERVICE VERSION 22/tcp open ssh OpenSSH 7.6p1 Ubuntu 4ubuntu0.3 (Ubuntu Linux; protocol 2.0) 25/tcp open smtp Postfix smtpd 80/tcp open http Apache httpd 2.4.29 ((Ubuntu)) 110/tcp open pop3 Dovecot pop3d 139/tcp filtered netbios-ssn 143/tcp open imap Dovecot imapd (Ubuntu) 445/tcp filtered microsoft-ds 993/tcp open ssl/imap Dovecot imapd (Ubuntu) 995/tcp open ssl/pop3 Dovecot pop3d MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) Service Info: Host: inlane; OS: Linux; CPE: cpe:/o:linux:linux_kernel # Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 91.73 seconds Scanning Options Description 10.129.2.28 Scans the specified target. -p- Scans all ports. -sV Performs service version detection on specified ports. Primarily, Nmap looks at the banners of the scanned ports and prints them out. If it cannot identify versions through the banners, Nmapattempts to identify them through a signature-based matching system, but this significantly increases the scan’s duration. One disadvantage to Nmap’s presented results is that the automatic scan can miss some information because sometimes Nmap does not know how to handle it. Let us look at an example of this. Service Enumeration notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p- -sV -Pn -n --disable-arp-ping --packet-trace # Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-16 20:10 CEST &lt;SNIP&gt; NSOCK INFO [0.4200s] nsock_trace_handler_callback(): Callback: READ SUCCESS for EID 18 [10.129.2.28:25] (35 bytes): 220 inlane ESMTP Postfix (Ubuntu).. Service scan match (Probe NULL matched with NULL line 3104): 10.129.2.28:25 is smtp. Version: |Postfix smtpd||| NSOCK INFO [0.4200s] nsock_iod_delete(): nsock_iod_delete (IOD #1) Nmap scan report for 10.129.2.28 Host is up (0.076s latency). # PORT STATE SERVICE VERSION 25/tcp open smtp Postfix smtpd MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) Service Info: Host: inlane # Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 0.47 seconds Scanning Options Description 10.129.2.28 Scans the specified target. -p- Scans all ports. -sV Performs service version detection on specified ports. -Pn Disables ICMP Echo requests. -n Disables DNS resolution. --disable-arp-ping Disables ARP ping. --packet-trace Shows all packets sent and received. If we look at the results from Nmap, we can see the port’s status, service name, and hostname. Nevertheless, let us look at this line here: NSOCK INFO [0.4200s] nsock_trace_handler_callback(): Callback: READ SUCCESS for EID 18 [10.129.2.28:25] (35 bytes): 220 inlane ESMTP Postfix (Ubuntu).. Then we see that the SMTP server on our target gave us more information than Nmap showed us. Because here, we see that it is the Linux distribution Ubuntu. It happens because, after a successful three-way handshake, the server often sends a banner for identification. This serves to let the client know which service it is working with. At the network level, this happens with a PSH flag in the TCP header. However, it can happen that some services do not immediately provide such information. It is also possible to remove or manipulate the banners from the respective services. If we manually connect to the SMTP server using nc, grab the banner, and intercept the network traffic using tcpdump, we can see what Nmap did not show us. 3.6.3 Tcpdump Service Enumeration notluken@htb[/htb]$ sudo tcpdump -i eth0 host 10.10.14.2 and 10.129.2.28 # tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes 3.6.4 Nc Service Enumeration notluken@htb[/htb]$ nc -nv 10.129.2.28 25 # Connection to 10.129.2.28 port 25 [tcp/*] succeeded! 220 inlane ESMTP Postfix (Ubuntu) 3.6.5 Tcpdump - Intercepted Traffic Service Enumeration 18:28:07.128564 IP 10.10.14.2.59618 &gt; 10.129.2.28.smtp: Flags [S], seq 1798872233, win 65535, options [mss 1460,nop,wscale 6,nop,nop,TS val 331260178 ecr 0,sackOK,eol], length 0 18:28:07.255151 IP 10.129.2.28.smtp &gt; 10.10.14.2.59618: Flags [S.], seq 1130574379, ack 1798872234, win 65160, options [mss 1460,sackOK,TS val 1800383922 ecr 331260178,nop,wscale 7], length 0 18:28:07.255281 IP 10.10.14.2.59618 &gt; 10.129.2.28.smtp: Flags [.], ack 1, win 2058, options [nop,nop,TS val 331260304 ecr 1800383922], length 0 18:28:07.319306 IP 10.129.2.28.smtp &gt; 10.10.14.2.59618: Flags [P.], seq 1:36, ack 1, win 510, options [nop,nop,TS val 1800383985 ecr 331260304], length 35: SMTP: 220 inlane ESMTP Postfix (Ubuntu) 18:28:07.319426 IP 10.10.14.2.59618 &gt; 10.129.2.28.smtp: Flags [.], ack 36, win 2058, options [nop,nop,TS val 331260368 ecr 1800383985], length 0 The first three lines show us the three-way handshake. 1. [SYN] 18:28:07.128564 IP 10.10.14.2.59618 &gt; 10.129.2.28.smtp: Flags [S], &lt;SNIP&gt; 2. [SYN-ACK] 18:28:07.255151 IP 10.129.2.28.smtp &gt; 10.10.14.2.59618: Flags [S.], &lt;SNIP&gt; 3. [ACK] 18:28:07.255281 IP 10.10.14.2.59618 &gt; 10.129.2.28.smtp: Flags [.], &lt;SNIP&gt; After that, the target SMTP server sends us a TCP packet with the PSH and ACK flags, where PSH states that the target server is sending data to us and with ACK simultaneously informs us that all required data has been sent. 4. [PSH-ACK] 18:28:07.319306 IP 10.129.2.28.smtp &gt; 10.10.14.2.59618: Flags [P.], &lt;SNIP&gt; The last TCP packet that we sent confirms the receipt of the data with an ACK. 5. [ACK] 18:28:07.319426 IP 10.10.14.2.59618 &gt; 10.129.2.28.smtp: Flags [.], &lt;SNIP&gt; 3.7 Nmap Scription Engine Nmap Scripting Engine (NSE) is another handy feature of Nmap. It provides us with the possibility to create scripts in Lua for interaction with certain services. There are a total of 14 categories into which these scripts can be divided: Category Description auth Determination of authentication credentials. broadcast Scripts, which are used for host discovery by broadcasting and the discovered hosts, can be automatically added to the remaining scans. brute Executes scripts that try to log in to the respective service by brute-forcing with credentials. default Default scripts executed by using the -sC option. discovery Evaluation of accessible services. dos These scripts are used to check services for denial of service vulnerabilities and are used less as it harms the services. exploit This category of scripts tries to exploit known vulnerabilities for the scanned port. external Scripts that use external services for further processing. fuzzer This uses scripts to identify vulnerabilities and unexpected packet handling by sending different fields, which can take much time. intrusive Intrusive scripts that could negatively affect the target system. malware Checks if some malware infects the target system. safe Defensive scripts that do not perform intrusive and destructive access. version Extension for service detection. vuln Identification of specific vulnerabilities. We have several ways to define the desired scripts in Nmap. 3.7.1 Default Scripts Nmap Scripting Engine notluken@htb[/htb]$ sudo nmap &lt;target&gt; -sC 3.7.2 Specific Scripts Category Nmap Scripting Engine notluken@htb[/htb]$ sudo nmap &lt;target&gt; --script &lt;category&gt; 3.7.3 Defined Scripts Nmap Scripting Engine notluken@htb[/htb]$ sudo nmap &lt;target&gt; --script &lt;script-name&gt;,&lt;script-name&gt;,... For example, let us keep working with the target SMTP port and see the results we get with two defined scripts. 3.7.4 Nmap - Specifying Scripts Nmap Scripting Engine notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p 25 --script banner,smtp-commands # Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-16 23:21 CEST Nmap scan report for 10.129.2.28 Host is up (0.050s latency). # PORT STATE SERVICE 25/tcp open smtp |_banner: 220 inlane ESMTP Postfix (Ubuntu) |_smtp-commands: inlane, PIPELINING, SIZE 10240000, VRFY, ETRN, STARTTLS, ENHANCEDSTATUSCODES, 8BITMIME, DSN, SMTPUTF8, MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) Scanning Options Description 10.129.2.28 Scans the specified target. -p 25 Scans only the specified port. --script banner,smtp-commands Uses specified NSE scripts. We see that we can recognize the Ubuntu distribution of Linux by using the’ banner’ script. The smtp-commands script shows us which commands we can use by interacting with the target SMTP server. In this example, such information may help us to find out existing users on the target. Nmap also gives us the ability to scan our target with the aggressive option (-A). This scans the target with multiple options as service detection (-sV), OS detection (-O), traceroute (--traceroute), and with the default NSE scripts (-sC). 3.7.5 Nmap - Aggressive Scan Nmap Scripting Engine notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p 80 -A Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-17 01:38 CEST Nmap scan report for 10.129.2.28 Host is up (0.012s latency). # PORT STATE SERVICE VERSION 80/tcp open http Apache httpd 2.4.29 ((Ubuntu)) |_http-generator: WordPress 5.3.4 |_http-server-header: Apache/2.4.29 (Ubuntu) |_http-title: blog.inlanefreight.com MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) Warning: OSScan results may be unreliable because we could not find at least 1 open and 1 closed port Aggressive OS guesses: Linux 2.6.32 (96%), Linux 3.2 - 4.9 (96%), Linux 2.6.32 - 3.10 (96%), Linux 3.4 - 3.10 (95%), Linux 3.1 (95%), Linux 3.2 (95%), AXIS 210A or 211 Network Camera (Linux 2.6.17) (94%), Synology DiskStation Manager 5.2-5644 (94%), Netgear RAIDiator 4.2.28 (94%), Linux 2.6.32 - 2.6.35 (94%) No exact OS matches for host (test conditions non-ideal). Network Distance: 1 hop # TRACEROUTE HOP RTT ADDRESS 1 11.91 ms 10.129.2.28 # OS and Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 11.36 seconds Scanning Options Description 10.129.2.28 Scans the specified target. -p 80 Scans only the specified port. -A Performs service detection, OS detection, traceroute and uses defaults scripts to scan the target. With the help of the used scan option (-A), we found out what kind of web server (Apache 2.4.29) is running on the system, which web application (WordPress 5.3.4) is used, and the title (blog.inlanefreight.com) of the web page. Also, Nmap shows that it is likely to be Linux (96%) operating system. 3.7.6 Vulnerability Assessment Now let us move on to HTTP port 80 and see what information and vulnerabilities we can find using the vuln category from NSE. 3.7.6.1 Nmap - Vuln Category Nmap Scripting Engine notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p 80 -sV --script vuln # Nmap scan report for 10.129.2.28 Host is up (0.036s latency). # PORT STATE SERVICE VERSION 80/tcp open http Apache httpd 2.4.29 ((Ubuntu)) | http-enum: | /wp-login.php: Possible admin folder | /readme.html: Wordpress version: 2 | /: WordPress version: 5.3.4 | /wp-includes/images/rss.png: Wordpress version 2.2 found. | /wp-includes/js/jquery/suggest.js: Wordpress version 2.5 found. | /wp-includes/images/blank.gif: Wordpress version 2.6 found. | /wp-includes/js/comment-reply.js: Wordpress version 2.7 found. | /wp-login.php: Wordpress login page. | /wp-admin/upgrade.php: Wordpress login page. |_ /readme.html: Interesting, a readme. |_http-server-header: Apache/2.4.29 (Ubuntu) |_http-stored-xss: Couldn&#39;t find any stored XSS vulnerabilities. | http-wordpress-users: | Username found: admin |_Search stopped at ID #25. Increase the upper limit if necessary with &#39;http-wordpress-users.limit&#39; | vulners: | cpe:/a:apache:http_server:2.4.29: | CVE-2019-0211 7.2 https://vulners.com/cve/CVE-2019-0211 | CVE-2018-1312 6.8 https://vulners.com/cve/CVE-2018-1312 | CVE-2017-15715 6.8 https://vulners.com/cve/CVE-2017-15715 &lt;SNIP&gt; Scanning Options Description 10.129.2.28 Scans the specified target. -p 80 Scans only the specified port. -sV Performs service version detection on specified ports. --script vuln Uses all related scripts from specified category. The scripts used for the last scan interact with the webserver and its web application to find out more information about their versions and check various databases to see if there are known vulnerabilities. More information about NSE scripts and the corresponding categories we can find at: https://nmap.org/nsedoc/index.html 3.8 Performance Scanning performance plays a significant role when we need to scan an extensive network or are dealing with low network bandwidth. We can use various options to tell Nmap how fast (-T &lt;0-5&gt;), with which frequency (--min-parallelism &lt;number&gt;), which timeouts (--max-rtt-timeout &lt;time&gt;) the test packets should have, how many packets should be sent simultaneously (--min-rate &lt;number&gt;), and with the number of retries (--max-retries &lt;number&gt;) for the scanned ports the targets should be scanned. 3.8.1 Timeouts When Nmap sends a packet, it takes some time (Round-Trip-Time - RTT) to receive a response from the scanned port. Generally, Nmapstarts with a high timeout (--min-RTT-timeout) of 100ms. Let us look at an example by scanning the whole network with 256 hosts, including the top 100 ports. 3.8.2 Default Scan Performance notluken@htb[/htb]$ sudo nmap 10.129.2.0/24 -F # &lt;SNIP&gt; Nmap done: 256 IP addresses (10 hosts up) scanned in 39.44 seconds 3.8.3 Optimized RTT Performance notluken@htb[/htb]$ sudo nmap 10.129.2.0/24 -F --initial-rtt-timeout 50ms --max-rtt-timeout 100ms # &lt;SNIP&gt; Nmap done: 256 IP addresses (8 hosts up) scanned in 12.29 seconds Scanning Options Description 10.129.2.0/24 Scans the specified target network. -F Scans top 100 ports. --initial-rtt-timeout 50ms Sets the specified time value as initial RTT timeout. --max-rtt-timeout 100ms Sets the specified time value as maximum RTT timeout. When comparing the two scans, we can see that we found two hosts less with the optimized scan, but the scan took only a quarter of the time. From this, we can conclude that setting the initial RTT timeout (--initial-rtt-timeout) to too short a time period may cause us to overlook hosts. 3.8.4 Max Retries Another way to increase scan speed is by specifying the retry rate of sent packets (--max-retries). The default value is 10, but we can reduce it to 0. This means if Nmap does not receive a response for a port, it won’t send any more packets to that port and will skip it. 3.8.5 Default Scan Performance notluken@htb[/htb]$ sudo nmap 10.129.2.0/24 -F | grep &quot;/tcp&quot; | wc -l # 23 3.8.6 Reduced Retries Performance notluken@htb[/htb]$ sudo nmap 10.129.2.0/24 -F --max-retries 0 | grep &quot;/tcp&quot; | wc -l # 21 Scanning Options Description 10.129.2.0/24 Scans the specified target network. -F Scans top 100 ports. --max-retries 0 Sets the number of retries that will be performed during the scan. Again, we recognize that accelerating can also have a negative effect on our results, which means we can overlook important information. 3.8.7 Rates During a white-box penetration test, we may get whitelisted for the security systems to check the systems in the network for vulnerabilities and not only test the protection measures. If we know the network bandwidth, we can work with the rate of packets sent, which significantly speeds up our scans with Nmap. When setting the minimum rate (--min-rate &lt;number&gt;) for sending packets, we tell Nmap to simultaneously send the specified number of packets. It will attempt to maintain the rate accordingly. 3.8.8 Default Scan Performance notluken@htb[/htb]$ sudo nmap 10.129.2.0/24 -F -oN tnet.default # &lt;SNIP&gt; Nmap done: 256 IP addresses (10 hosts up) scanned in 29.83 seconds 3.8.9 Optimized Scan Performance notluken@htb[/htb]$ sudo nmap 10.129.2.0/24 -F -oN tnet.minrate300 --min-rate 300 # &lt;SNIP&gt; Nmap done: 256 IP addresses (10 hosts up) scanned in 8.67 seconds Scanning Options Description 10.129.2.0/24 Scans the specified target network. -F Scans top 100 ports. -oN tnet.minrate300 Saves the results in normal formats, starting the specified file name. --min-rate 300 Sets the minimum number of packets to be sent per second. 3.8.10 Default Scan - Found Open Ports Performance notluken@htb[/htb]$ cat tnet.default | grep &quot;/tcp&quot; | wc -l # 23 3.8.11 Optimized Scan - Found Open Ports Performance notluken@htb[/htb]$ cat tnet.minrate300 | grep &quot;/tcp&quot; | wc -l 23 3.8.12 Timing Because such settings cannot always be optimized manually, as in a black-box penetration test, Nmap offers six different timing templates (-T &lt;0-5&gt;) for us to use. These values (0-5) determine the aggressiveness of our scans. This can also have negative effects if the scan is too aggressive, and security systems may block us due to the produced network traffic. The default timing template used when we have defined nothing else is the normal (-T 3). -T 0 / -T paranoid -T 1 / -T sneaky -T 2 / -T polite -T 3 / -T normal -T 4 / -T aggressive -T 5 / -T insane These templates contain options that we can also set manually, and have seen some of them already. The developers determined the values set for these templates according to their best results, making it easier for us to adapt our scans to the corresponding network environment. The exact used options with their values we can find here: https://nmap.org/book/performance-timing-templates.html 3.8.12.1 Default Scan Performance notluken@htb[/htb]$ sudo nmap 10.129.2.0/24 -F -oN tnet.default # &lt;SNIP&gt; Nmap done: 256 IP addresses (10 hosts up) scanned in 32.44 seconds 3.8.12.2 Insane Scan Performance notluken@htb[/htb]$ sudo nmap 10.129.2.0/24 -F -oN tnet.T5 -T 5 &lt;SNIP&gt; Nmap done: 256 IP addresses (10 hosts up) scanned in 18.07 seconds Scanning Options Description 10.129.2.0/24 Scans the specified target network. -F Scans top 100 ports. -oN tnet.T5 Saves the results in normal formats, starting the specified file name. -T 5 Specifies the insane timing template. 3.8.12.3 Default Scan - Found Open Ports Performance notluken@htb[/htb]$ cat tnet.default | grep &quot;/tcp&quot; | wc -l 23 3.8.12.4 Insane Scan - Found Open Ports notluken@htb[/htb]$ cat tnet.T5 | grep &quot;/tcp&quot; | wc -l 23 3.9 Firewall and IDS-IPS Evasion Nmap gives us many different ways to bypass firewalls rules and IDS/IPS. These methods include the fragmentation of packets, the use of decoys, and others that we will discuss in this section. 3.9.1 Firewalls A firewall is a security measure against unauthorized connection attempts from external networks. Every firewall security system is based on a software component that monitors network traffic between the firewall and incoming data connections and decides how to handle the connection based on the rules that have been set. It checks whether individual network packets are being passed, ignored, or blocked. This mechanism is designed to prevent unwanted connections that could be potentially dangerous. 3.9.2 IDS/IPS Like the firewall, the intrusion detection system (IDS) and intrusion prevention system (IPS) are also software-based components. IDSscans the network for potential attacks, analyzes them, and reports any detected attacks. IPS complements IDS by taking specific defensive measures if a potential attack should have been detected. The analysis of such attacks is based on pattern matching and signatures. If specific patterns are detected, such as a service detection scan, IPS may prevent the pending connection attempts. 3.9.3 Determine Firewalls and Their Rules We already know that when a port is shown as filtered, it can have several reasons. In most cases, firewalls have certain rules set to handle specific connections. The packets can either be dropped, or rejected. The dropped packets are ignored, and no response is returned from the host. This is different for rejected packets that are returned with an RST flag. These packets contain different types of ICMP error codes or contain nothing at all. Such errors can be: Net Unreachable Net Prohibited Host Unreachable Host Prohibited Port Unreachable Proto Unreachable Nmap’s TCP ACK scan (-sA) method is much harder to filter for firewalls and IDS/IPS systems than regular SYN (-sS) or Connect scans (sT) because they only send a TCP packet with only the ACK flag. When a port is closed or open, the host must respond with an RST flag. Unlike outgoing connections, all connection attempts (with the SYN flag) from external networks are usually blocked by firewalls. However, the packets with the ACK flag are often passed by the firewall because the firewall cannot determine whether the connection was first established from the external network or the internal network. If we look at these scans, we will see how the results differ. 3.9.3.1 SYN-Scan Firewall and IDS/IPS Evasion notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p 21,22,25 -sS -Pn -n --disable-arp-ping --packet-trace Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-21 14:56 CEST SENT (0.0278s) TCP 10.10.14.2:57347 &gt; 10.129.2.28:22 S ttl=53 id=22412 iplen=44 seq=4092255222 win=1024 &lt;mss 1460&gt; SENT (0.0278s) TCP 10.10.14.2:57347 &gt; 10.129.2.28:25 S ttl=50 id=62291 iplen=44 seq=4092255222 win=1024 &lt;mss 1460&gt; SENT (0.0278s) TCP 10.10.14.2:57347 &gt; 10.129.2.28:21 S ttl=58 id=38696 iplen=44 seq=4092255222 win=1024 &lt;mss 1460&gt; RCVD (0.0329s) ICMP [10.129.2.28 &gt; 10.10.14.2 Port 21 unreachable (type=3/code=3) ] IP [ttl=64 id=40884 iplen=72 ] RCVD (0.0341s) TCP 10.129.2.28:22 &gt; 10.10.14.2:57347 SA ttl=64 id=0 iplen=44 seq=1153454414 win=64240 &lt;mss 1460&gt; RCVD (1.0386s) TCP 10.129.2.28:22 &gt; 10.10.14.2:57347 SA ttl=64 id=0 iplen=44 seq=1153454414 win=64240 &lt;mss 1460&gt; SENT (1.1366s) TCP 10.10.14.2:57348 &gt; 10.129.2.28:25 S ttl=44 id=6796 iplen=44 seq=4092320759 win=1024 &lt;mss 1460&gt; Nmap scan report for 10.129.2.28 Host is up (0.0053s latency). PORT STATE SERVICE 21/tcp filtered ftp 22/tcp open ssh 25/tcp filtered smtp MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) Nmap done: 1 IP address (1 host up) scanned in 0.07 seconds 3.9.3.2 ACK-Scan Firewall and IDS/IPS Evasion notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p 21,22,25 -sA -Pn -n --disable-arp-ping --packet-trace Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-21 14:57 CEST SENT (0.0422s) TCP 10.10.14.2:49343 &gt; 10.129.2.28:21 A ttl=49 id=12381 iplen=40 seq=0 win=1024 SENT (0.0423s) TCP 10.10.14.2:49343 &gt; 10.129.2.28:22 A ttl=41 id=5146 iplen=40 seq=0 win=1024 SENT (0.0423s) TCP 10.10.14.2:49343 &gt; 10.129.2.28:25 A ttl=49 id=5800 iplen=40 seq=0 win=1024 RCVD (0.1252s) ICMP [10.129.2.28 &gt; 10.10.14.2 Port 21 unreachable (type=3/code=3) ] IP [ttl=64 id=55628 iplen=68 ] RCVD (0.1268s) TCP 10.129.2.28:22 &gt; 10.10.14.2:49343 R ttl=64 id=0 iplen=40 seq=1660784500 win=0 SENT (1.3837s) TCP 10.10.14.2:49344 &gt; 10.129.2.28:25 A ttl=59 id=21915 iplen=40 seq=0 win=1024 Nmap scan report for 10.129.2.28 Host is up (0.083s latency). PORT STATE SERVICE 21/tcp filtered ftp 22/tcp unfiltered ssh 25/tcp filtered smtp MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) Nmap done: 1 IP address (1 host up) scanned in 0.15 seconds Scanning Options Description 10.129.2.28 Scans the specified target. -p 21,22,25 Scans only the specified ports. -sS Performs SYN scan on specified ports. -sA Performs ACK scan on specified ports. -Pn Disables ICMP Echo requests. -n Disables DNS resolution. --disable-arp-ping Disables ARP ping. --packet-trace Shows all packets sent and received. Please pay attention to the RCVD packets and its set flag we receive from our target. With the SYN scan (-sS) our target tries to establish the TCP connection by sending a packet back with the SYN-ACK (SA) flags set and with the ACK scan (-sA) we get the RSTflag because TCP port 22 is open. For the TCP port 25, we do not receive any packets back, which indicates that the packets will be dropped. 3.9.4 Detect IDS/IPS Unlike firewalls and their rules, the detection of IDS/IPS systems is much more difficult because these are passive traffic monitoring systems. IDS systems examine all connections between hosts. If the IDS finds packets containing the defined contents or specifications, the administrator is notified and takes appropriate action in the worst case. IPS systems take measures configured by the administrator independently to prevent potential attacks automatically. It is essential to know that IDS and IPS are different applications and that IPS serves as a complement to IDS. Several virtual private servers (VPS) with different IP addresses are recommended to determine whether such systems are on the target network during a penetration test. If the administrator detects such a potential attack on the target network, the first step is to block the IP address from which the potential attack comes. As a result, we will no longer be able to access the network using that IP address, and our Internet Service Provider (ISP) will be contacted and blocked from all access to the Internet. IDS systems alone are usually there to help administrators detect potential attacks on their network. They can then decide how to handle such connections. We can trigger certain security measures from an administrator, for example, by aggressively scanning a single port and its service. Based on whether specific security measures are taken, we can detect if the network has some monitoring applications or not. One method to determine whether such IPS system is present in the target network is to scan from a single host (VPS). If at any time this host is blocked and has no access to the target network, we know that the administrator has taken some security measures. Accordingly, we can continue our penetration test with another VPS. Consequently, we know that we need to be quieter with our scans and, in the best case, disguise all interactions with the target network and its services. 3.9.5 Decoys There are cases in which administrators block specific subnets from different regions in principle. This prevents any access to the target network. Another example is when IPS should block us. For this reason, the Decoy scanning method (-D) is the right choice. With this method, Nmap generates various random IP addresses inserted into the IP header to disguise the origin of the packet sent. With this method, we can generate random (RND) a specific number (for example: 5) of IP addresses separated by a colon (:). Our real IP address is then randomly placed between the generated IP addresses. In the next example, our real IP address is therefore placed in the second position. Another critical point is that the decoys must be alive. Otherwise, the service on the target may be unreachable due to SYN-flooding security mechanisms. 3.9.5.1 Scan by Using Decoys Firewall and IDS/IPS Evasion notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p 80 -sS -Pn -n --disable-arp-ping --packet-trace -D RND:5 # Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-21 16:14 CEST SENT (0.0378s) TCP 102.52.161.59:59289 &gt; 10.129.2.28:80 S ttl=42 id=29822 iplen=44 seq=3687542010 win=1024 &lt;mss 1460&gt; SENT (0.0378s) TCP 10.10.14.2:59289 &gt; 10.129.2.28:80 S ttl=59 id=29822 iplen=44 seq=3687542010 win=1024 &lt;mss 1460&gt; SENT (0.0379s) TCP 210.120.38.29:59289 &gt; 10.129.2.28:80 S ttl=37 id=29822 iplen=44 seq=3687542010 win=1024 &lt;mss 1460&gt; SENT (0.0379s) TCP 191.6.64.171:59289 &gt; 10.129.2.28:80 S ttl=38 id=29822 iplen=44 seq=3687542010 win=1024 &lt;mss 1460&gt; SENT (0.0379s) TCP 184.178.194.209:59289 &gt; 10.129.2.28:80 S ttl=39 id=29822 iplen=44 seq=3687542010 win=1024 &lt;mss 1460&gt; SENT (0.0379s) TCP 43.21.121.33:59289 &gt; 10.129.2.28:80 S ttl=55 id=29822 iplen=44 seq=3687542010 win=1024 &lt;mss 1460&gt; RCVD (0.1370s) TCP 10.129.2.28:80 &gt; 10.10.14.2:59289 SA ttl=64 id=0 iplen=44 seq=4056111701 win=64240 &lt;mss 1460&gt; Nmap scan report for 10.129.2.28 Host is up (0.099s latency). # PORT STATE SERVICE 80/tcp open http MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) # Nmap done: 1 IP address (1 host up) scanned in 0.15 seconds Scanning Options Description 10.129.2.28 Scans the specified target. -p 80 Scans only the specified ports. -sS Performs SYN scan on specified ports. -Pn Disables ICMP Echo requests. -n Disables DNS resolution. --disable-arp-ping Disables ARP ping. --packet-trace Shows all packets sent and received. -D RND:5 Generates five random IP addresses that indicates the source IP the connection comes from. The spoofed packets are often filtered out by ISPs and routers, even though they come from the same network range. Therefore, we can also specify our VPS servers’ IP addresses and use them in combination with “IP ID” manipulation in the IP headers to scan the target. Another scenario would be that only individual subnets would not have access to the server’s specific services. So we can also manually specify the source IP address (-S) to test if we get better results with this one. Decoys can be used for SYN, ACK, ICMP scans, and OS detection scans. So let us look at such an example and determine which operating system it is most likely to be. 3.9.5.2 Testing Firewall Rule Firewall and IDS/IPS Evasion notluken@htb[/htb]$ sudo nmap 10.129.2.28 -n -Pn -p445 -O # Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-22 01:23 CEST Nmap scan report for 10.129.2.28 Host is up (0.032s latency). # PORT STATE SERVICE 445/tcp filtered microsoft-ds MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) Too many fingerprints match this host to give specific OS details Network Distance: 1 hop # OS detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 3.14 seconds 3.9.5.3 Scan by Using Different Source IP Firewall and IDS/IPS Evasion notluken@htb[/htb]$ sudo nmap 10.129.2.28 -n -Pn -p 445 -O -S 10.129.2.200 -e tun0 # Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-22 01:16 CEST Nmap scan report for 10.129.2.28 Host is up (0.010s latency). # PORT STATE SERVICE 445/tcp open microsoft-ds MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) Warning: OSScan results may be unreliable because we could not find at least 1 open and 1 closed port Aggressive OS guesses: Linux 2.6.32 (96%), Linux 3.2 - 4.9 (96%), Linux 2.6.32 - 3.10 (96%), Linux 3.4 - 3.10 (95%), Linux 3.1 (95%), Linux 3.2 (95%), AXIS 210A or 211 Network Camera (Linux 2.6.17) (94%), Synology DiskStation Manager 5.2-5644 (94%), Linux 2.6.32 - 2.6.35 (94%), Linux 2.6.32 - 3.5 (94%) No exact OS matches for host (test conditions non-ideal). Network Distance: 1 hop # OS detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 4.11 seconds Scanning Options Description 10.129.2.28 Scans the specified target. -n Disables DNS resolution. -Pn Disables ICMP Echo requests. -p 445 Scans only the specified ports. -O Performs operation system detection scan. -S Scans the target by using different source IP address. 10.129.2.200 Specifies the source IP address. -e tun0 Sends all requests through the specified interface. 3.9.6 DNS Proxying By default, Nmap performs a reverse DNS resolution unless otherwise specified to find more important information about our target. These DNS queries are also passed in most cases because the given web server is supposed to be found and visited. The DNS queries are made over the UDP port 53. The TCP port 53 was previously only used for the so-called “Zone transfers” between the DNS servers or data transfer larger than 512 bytes. More and more, this is changing due to IPv6 and DNSSEC expansions. These changes cause many DNS requests to be made via TCP port 53. However, Nmap still gives us a way to specify DNS servers ourselves (--dns-server &lt;ns&gt;,&lt;ns&gt;). This method could be fundamental to us if we are in a demilitarized zone (DMZ). The company’s DNS servers are usually more trusted than those from the Internet. So, for example, we could use them to interact with the hosts of the internal network. As another example, we can use TCP port 53 as a source port (--source-port) for our scans. If the administrator uses the firewall to control this port and does not filter IDS/IPS properly, our TCP packets will be trusted and passed through. nmap -sSU -p 53 --script dns-nsid 3.9.6.1 SYN-Scan of a Filtered Port Firewall and IDS/IPS Evasion notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p50000 -sS -Pn -n --disable-arp-ping --packet-trace # Starting Nmap 7.80 ( https://nmap.org ) at 2020-06-21 22:50 CEST SENT (0.0417s) TCP 10.10.14.2:33436 &gt; 10.129.2.28:50000 S ttl=41 id=21939 iplen=44 seq=736533153 win=1024 &lt;mss 1460&gt; SENT (1.0481s) TCP 10.10.14.2:33437 &gt; 10.129.2.28:50000 S ttl=46 id=6446 iplen=44 seq=736598688 win=1024 &lt;mss 1460&gt; Nmap scan report for 10.129.2.28 Host is up. # PORT STATE SERVICE 50000/tcp filtered ibm-db2 # Nmap done: 1 IP address (1 host up) scanned in 2.06 seconds 3.9.6.2 SYN-Scan From DNS Port Firewall and IDS/IPS Evasion notluken@htb[/htb]$ sudo nmap 10.129.2.28 -p50000 -sS -Pn -n --disable-arp-ping --packet-trace --source-port 53 # SENT (0.0482s) TCP 10.10.14.2:53 &gt; 10.129.2.28:50000 S ttl=58 id=27470 iplen=44 seq=4003923435 win=1024 &lt;mss 1460&gt; RCVD (0.0608s) TCP 10.129.2.28:50000 &gt; 10.10.14.2:53 SA ttl=64 id=0 iplen=44 seq=540635485 win=64240 &lt;mss 1460&gt; Nmap scan report for 10.129.2.28 Host is up (0.013s latency). # PORT STATE SERVICE 50000/tcp open ibm-db2 MAC Address: DE:AD:00:00:BE:EF (Intel Corporate) # Nmap done: 1 IP address (1 host up) scanned in 0.08 seconds Scanning Options Description 10.129.2.28 Scans the specified target. -p 50000 Scans only the specified ports. -sS Performs SYN scan on specified ports. -Pn Disables ICMP Echo requests. -n Disables DNS resolution. --disable-arp-ping Disables ARP ping. --packet-trace Shows all packets sent and received. --source-port 53 Performs the scans from specified source port. Now that we have found out that the firewall accepts TCP port 53, it is very likely that IDS/IPS filters might also be configured much weaker than others. We can test this by trying to connect to this port by using Netcat. 3.9.6.3 Connect To The Filtered Port Firewall and IDS/IPS Evasion notluken@htb[/htb]$ ncat -nv --source-port 53 10.129.2.28 50000 Ncat: Version 7.80 ( https://nmap.org/ncat ) Ncat: Connected to 10.129.2.28:50000. 220 ProFTPd "],["enumeration-principles.html", "4 Enumeration Principles 4.1 Enumeration Principles 4.2 Enumeration Metodology 4.3 Domain Information 4.4 Cloud Resources", " 4 Enumeration Principles 4.1 Enumeration Principles Enumeration is a widely used term in cyber security. It stands for information gathering using active (scans) and passive (use of third-party providers) methods. It is important to note that OSINT is an independent procedure and should be performed separately from enumeration because OSINT is based exclusively on passive information gathering and does not involve active enumeration of the given target. Enumeration is a loop in which we repeatedly gather information based on what data we have or have already discovered. Information can be gathered from domains, IP addresses, accessible services, and many other sources. Once we have identified targets in our client’s infrastructure, we need to examine the individual services and protocols. In most cases, these are services that enable communication between customers, the infrastructure, the administration, and the employees. If we imagine that we have been hired to investigate the IT security of a company, we will start to develop a general understanding of the company’s functionality. For example, we need to understand how the company is structured, what services and third-party vendors it uses, what security measures may be in place, and more. This is where this stage can be a bit misunderstood because most people focus on the obvious and try to force their way into the company’s systems instead of understanding how the infrastructure is set up and what technical aspects and services are necessary to be able to offer a specific service. An example of such a wrong approach could be that after finding authentication services like SSH, RDP, WinRM, and the like, we try to brute-force with common/weak passwords and usernames. Unfortunately, brute-forcing is a noisy method and can easily lead to blacklisting, making further testing impossible. Primarily, this can happen if we do not know about the company’s defensive security measures and its infrastructure. Some may smile at this approach, but experience has shown that far too many testers take this type of approach. Our goal is not to get at the systems but to find all the ways to get there. We can think of this as an analogy of a treasure hunter preparing for his expedition. He would not just grab a shovel and start digging in some random spot, but he would plan and gather his gear and study maps and learn about the terrain he has to cover and where the treasure may be so he can bring the proper tools. If he goes around digging holes everywhere, he will cause damage, waste time and energy, and likely never achieve his goal. The same can be said for understanding a company’s internal and external infrastructure, mapping it out, and carefully formulating our plan of attack. The enumeration principles are based on some questions that will facilitate all our investigations in any conceivable situation. In most cases, the main focus of many penetration testers is on what they can see and not on what they cannot see. However, even what we cannot see is relevant to us and may well be of great importance. The difference here is that we start to see the components and aspects that are not visible at first glance with our experience. What can we see? What reasons can we have for seeing it? What image does what we see create for us? What do we gain from it? How can we use it? What can we not see? What reasons can there be that we do not see? What image results for us from what we do not see? An important aspect that must not be confused here is that there are always exceptions to the rules. The principles, however, do not change. Another advantage of these principles is that we can see from the practical tasks that we do not lack penetration testing abilities but technical understanding when we suddenly do not know how to proceed because our core task is not to exploit the machines but to find how they can be exploited. No. Principle 1. There is more than meets the eye. Consider all points of view. 2. Distinguish between what we see and what we do not see. 3. There are always ways to gain more information. Understand the target. To familiarize ourselves with these principles, we should write down these questions and principles where we can always see them and refer back to them with ease. 4.2 Enumeration Metodology Complex processes must have a standardized methodology that helps us keep our bearings and avoid omitting any aspects by mistake. Especially with the variety of cases that the target systems can offer us, it is almost unpredictable how our approach should be designed. Therefore, most penetration testers follow their habits and the steps they feel most comfortable and familiar with. However, this is not a standardized methodology but rather an experience-based approach. We know that penetration testing, and therefore enumeration, is a dynamic process. Consequently, we have developed a static enumeration methodology for external and internal penetration tests that includes free dynamics and allows for a wide range of changes and adaptations to the given environment. This methodology is nested in 6 layers and represents, metaphorically speaking, boundaries that we try to pass with the enumeration process. The whole enumeration process is divided into three different levels: Infrastructure-based enumeration Host-based enumeration OS-based enumeration image Note: The components of each layer shown represent the main categories and not a full list of all the components to search for. Additionally, it must be mentioned here that the first and second layer (Internet Presence, Gateway) does not quite apply to the intranet, such as an Active Directory infrastructure. The layers for internal infrastructure will be covered in other modules. Consider these lines as some kind of obstacle, like a wall, for example. What we do here is look around to find out where the entrance is, or the gap we can fit through, or climb over to get closer to our goal. Theoretically, it is also possible to go through the wall headfirst, but very often, it happens that the spot we have smashed the gap with a lot of effort and time with force does not bring us much because there is no entry at this point of the wall to pass on to the next wall. These layers are designed as follows: Layer Description Information Categories 1. Internet Presence Identification of internet presence and externally accessible infrastructure. Domains, Subdomains, vHosts, ASN, Netblocks, IP Addresses, Cloud Instances, Security Measures 2. Gateway Identify the possible security measures to protect the company’s external and internal infrastructure. Firewalls, DMZ, IPS/IDS, EDR, Proxies, NAC, Network Segmentation, VPN, Cloudflare 3. Accessible Services Identify accessible interfaces and services that are hosted externally or internally. Service Type, Functionality, Configuration, Port, Version, Interface 4. Processes Identify the internal processes, sources, and destinations associated with the services. PID, Processed Data, Tasks, Source, Destination 5. Privileges Identification of the internal permissions and privileges to the accessible services. Groups, Users, Permissions, Restrictions, Environment 6. OS Setup Identification of the internal components and systems setup. OS Type, Patch Level, Network config, OS Environment, Configuration files, sensitive private files Important note: The human aspect and the information that can be obtained by employees using OSINT have been removed from the “Internet Presence” layer for simplicity. We can finally imagine the entire penetration test in the form of a labyrinth where we have to identify the gaps and find the way to get us inside as quickly and effectively as possible. This type of labyrinth may look something like this: image The squares represent the gaps/vulnerabilities. As we have probably already noticed, we can see that we will encounter one gap and very likely several. The interesting and very common fact is that not all the gaps we find can lead us inside. All penetration tests are limited in time, but we should always keep in mind that one belief that there is nearly always a way in. Even after a four-week penetration test, we cannot say 100% that there are no more vulnerabilities. Someone who has been studying the company for months and analyzing them will most likely have a much greater understanding of the applications and structure than we were able to gain within the few weeks we spent on the assessment. An excellent and recent example of this is the cyber attack on SolarWinds, which happened not too long ago. This is another excellent reason for a methodology that must exclude such cases. Let us assume that we have been asked to perform an external “black box” penetration test. Once all the necessary contract items have been completely fulfilled, our penetration test will begin at the specified time. 4.2.1 Layer No.1: Internet Presence The first layer we have to pass is the “Internet Presence” layer, where we focus on finding the targets we can investigate. If the scope in the contract allows us to look for additional hosts, this layer is even more critical than for fixed targets only. In this layer, we use different techniques to find domains, subdomains, netblocks, and many other components and information that present the presence of the company and its infrastructure on the Internet. The goal of this layer is to identify all possible target systems and interfaces that can be tested.  4.2.2 Layer No.2: Gateway Here we try to understand the interface of the reachable target, how it is protected, and where it is located in the network. Due to the diversity, different functionalities, and some particular procedures, we will go into more detail about this layer in other modules. The goal is to understand what we are dealing with and what we have to watch out for. 4.2.3 Layer No.3: Accessible Services In the case of accessible services, we examine each destination for all the services it offers. Each of these services has a specific purpose that has been installed for a particular reason by the administrator. Each service has certain functions, which therefore also lead to specific results. To work effectively with them, we need to know how they work. Otherwise, we need to learn to understand them. This layer aims to understand the reason and functionality of the target system and gain the necessary knowledge to communicate with it and exploit it for our purposes effectively. This is the part of enumeration we will mainly deal with in this module. 4.2.4 Layer No.4: Processes Every time a command or function is executed, data is processed, whether entered by the user or generated by the system. This starts a process that has to perform specific tasks, and such tasks have at least one source and one target. The goal here is to understand these factors and identify the dependencies between them. 4.2.5 Layer No.5: Privileges Each service runs through a specific user in a particular group with permissions and privileges defined by the administrator or the system. These privileges often provide us with functions that administrators overlook. This often happens in Active Directory infrastructures and many other case-specific administration environments and servers where users are responsible for multiple administration areas. It is crucial to identify these and understand what is and is not possible with these privileges. 4.2.6 Layer No.6: OS Setup Here we collect information about the actual operating system and its setup using internal access. This gives us a good overview of the internal security of the systems and reflects the skills and capabilities of the company’s administrative teams. The goal here is to see how the administrators manage the systems and what sensitive internal information we can glean from them. 4.2.7 Enumeration Methodology in Practice A methodology summarizes all systematic procedures in obtaining knowledge within the bounds of a given objective. It is important to note that a methodology is not a step-by-step guide but, as the definition implies, a summary of systematic procedures. In our case, the enumeration methodology is the systematic approach to explore a given target. How the individual components are identified and information obtained in this methodology is a dynamic and growing aspect that is constantly changing and can therefore differ. An excellent example of this is using information-gathering tools from web servers. There are countless different tools for this, and each of them has a specific focus and therefore delivers individual results that differ from other applications. The goal, however, is the same. Thus, the collection of tools and commands is not part of the actual methodology but rather a cheat sheet that we can refer to using the commands and tools listed in given cases. 4.3 Domain Information Domain information is a core component of any penetration test, and it is not just about the subdomains but about the entire presence on the Internet. Therefore, we gather information and try to understand the company’s functionality and which technologies and structures are necessary for services to be offered successfully and efficiently. This type of information is gathered passively without direct and active scans. In other words, we remain hidden and navigate as “customers” or “visitors” to avoid direct connections to the company that could expose us. The OSINT relevant sections are only a tiny part of how in-depth OSINT goes and describe only a few of the many ways to obtain information in this way. More approaches and strategies for this can be found in the module OSINT: Corporate Recon. However, when passively gathering information, we can use third-party services to understand the company better. However, the first thing we should do is scrutinize the company’s main website. Then, we should read through the texts, keeping in mind what technologies and structures are needed for these services. For example, many IT companies offer app development, IoT, hosting, data science, and IT security services, depending on their industry. If we encounter a service that we have had little to do with before, it makes sense and is necessary to get to grips with it and find out what activities it consists of and what opportunities are available. Those services also give us a good overview of how the company can be structured. For example, this part is the combination between the first principle and the second principle of enumeration. We pay attention to what we see and we do not see. We see the services but not their functionality. However, services are bound to certain technical aspects necessary to provide a service. Therefore, we take the developer’s view and look at the whole thing from their point of view. This point of view allows us to gain many technical insights into the functionality. 4.3.1 Online Presence Once we have a basic understanding of the company and its services, we can get a first impression of its presence on the Internet. Let us assume that a medium-sized company has hired us to test their entire infrastructure from a black-box perspective. This means we have only received a scope of targets and must obtain all further information ourselves. Note: Please remember that the examples below will differ from the practical exercises and will not give the same results. However, the examples are based on real penetration tests and illustrate how and what information can be obtained. The first point of presence on the Internet may be the SSL certificate from the company’s main website that we can examine. Often, such a certificate includes more than just a subdomain, and this means that the certificate is used for several domains, and these are most likely still active. Another source to find more subdomains is crt.sh. This source is Certificate Transparency logs. Certificate Transparency is a process that is intended to enable the verification of issued digital certificates for encrypted Internet connections. The standard (RFC 6962) provides for the logging of all digital certificates issued by a certificate authority in audit-proof logs. This is intended to enable the detection of false or maliciously issued certificates for a domain. SSL certificate providers like Let’s Encrypt share this with the web interface crt.sh, which stores the new entries in the database to be accessed later.     We can also output the results in JSON format. 4.3.2 Certificate Transparency   Domain Information notluken@htb[/htb]$ curl -s https://crt.sh/\\?q\\=inlanefreight.com\\&amp;output\\=json | jq . [ { &quot;issuer_ca_id&quot;: 23451835427, &quot;issuer_name&quot;: &quot;C=US, O=Let&#39;s Encrypt, CN=R3&quot;, &quot;common_name&quot;: &quot;matomo.inlanefreight.com&quot;, &quot;name_value&quot;: &quot;matomo.inlanefreight.com&quot;, &quot;id&quot;: 50815783237226155, &quot;entry_timestamp&quot;: &quot;2021-08-21T06:00:17.173&quot;, &quot;not_before&quot;: &quot;2021-08-21T05:00:16&quot;, &quot;not_after&quot;: &quot;2021-11-19T05:00:15&quot;, &quot;serial_number&quot;: &quot;03abe9017d6de5eda90&quot; }, { &quot;issuer_ca_id&quot;: 6864563267, &quot;issuer_name&quot;: &quot;C=US, O=Let&#39;s Encrypt, CN=R3&quot;, &quot;common_name&quot;: &quot;matomo.inlanefreight.com&quot;, &quot;name_value&quot;: &quot;matomo.inlanefreight.com&quot;, &quot;id&quot;: 5081529377, &quot;entry_timestamp&quot;: &quot;2021-08-21T06:00:16.932&quot;, &quot;not_before&quot;: &quot;2021-08-21T05:00:16&quot;, &quot;not_after&quot;: &quot;2021-11-19T05:00:15&quot;, &quot;serial_number&quot;: &quot;03abe90104e271c98a90&quot; }, { &quot;issuer_ca_id&quot;: 113123452, &quot;issuer_name&quot;: &quot;C=US, O=Let&#39;s Encrypt, CN=R3&quot;, &quot;common_name&quot;: &quot;smartfactory.inlanefreight.com&quot;, &quot;name_value&quot;: &quot;smartfactory.inlanefreight.com&quot;, &quot;id&quot;: 4941235512141012357, &quot;entry_timestamp&quot;: &quot;2021-07-27T00:32:48.071&quot;, &quot;not_before&quot;: &quot;2021-07-26T23:32:47&quot;, &quot;not_after&quot;: &quot;2021-10-24T23:32:45&quot;, &quot;serial_number&quot;: &quot;044bac5fcc4d59329ecbbe9043dd9d5d0878&quot; }, { ... SNIP ... If needed, we can also have them filtered by the unique subdomains.   Domain Information notluken@htb[/htb]$ curl -s https://crt.sh/\\?q\\=inlanefreight.com\\&amp;output\\=json | jq . | grep name | cut -d&quot;:&quot; -f2 | grep -v &quot;CN=&quot; | cut -d&#39;&quot;&#39; -f2 | awk &#39;{gsub(/\\\\n/,&quot;\\n&quot;);}1;&#39; | sort -u account.ttn.inlanefreight.com blog.inlanefreight.com bots.inlanefreight.com console.ttn.inlanefreight.com ct.inlanefreight.com data.ttn.inlanefreight.com *.inlanefreight.com inlanefreight.com integrations.ttn.inlanefreight.com iot.inlanefreight.com mails.inlanefreight.com marina.inlanefreight.com marina-live.inlanefreight.com matomo.inlanefreight.com next.inlanefreight.com noc.ttn.inlanefreight.com preview.inlanefreight.com shop.inlanefreight.com smartfactory.inlanefreight.com ttn.inlanefreight.com vx.inlanefreight.com www.inlanefreight.com Next, we can identify the hosts directly accessible from the Internet and not hosted by third-party providers. This is because we are not allowed to test the hosts without the permission of third-party providers. 4.3.3 Company Hosted Servers   Domain Information notluken@htb[/htb]$ for i in $(cat subdomainlist);do host $i | grep &quot;has address&quot; | grep inlanefreight.com | cut -d&quot; &quot; -f1,4;done blog.inlanefreight.com 10.129.24.93 inlanefreight.com 10.129.27.33 matomo.inlanefreight.com 10.129.127.22 www.inlanefreight.com 10.129.127.33 s3-website-us-west-2.amazonaws.com 10.129.95.250 Once we see which hosts can be investigated further, we can generate a list of IP addresses with a minor adjustment to the cut command and run them through Shodan. Shodan can be used to find devices and systems permanently connected to the Internet like Internet of Things (IoT). It searches the Internet for open TCP/IP ports and filters the systems according to specific terms and criteria. For example, open HTTP or HTTPS ports and other server ports for FTP, SSH, SNMP, Telnet, RTSP, or SIP are searched. As a result, we can find devices and systems, such as surveillance cameras, servers, smart home systems, industrial controllers, traffic lights and traffic controllers, and various network components. 4.3.4 Shodan - IP List   Domain Information notluken@htb[/htb]$ for i in $(cat subdomainlist);do host $i | grep &quot;has address&quot; | grep inlanefreight.com | cut -d&quot; &quot; -f4 &gt;&gt; ip-addresses.txt;done notluken@htb[/htb]$ for i in $(cat ip-addresses.txt);do shodan host $i;done 10.129.24.93 City: Berlin Country: Germany Organization: InlaneFreight Updated: 2021-09-01T09:02:11.370085 Number of open ports: 2 Ports: 80/tcp nginx 443/tcp nginx 10.129.27.33 City: Berlin Country: Germany Organization: InlaneFreight Updated: 2021-08-30T22:25:31.572717 Number of open ports: 3 Ports: 22/tcp OpenSSH (7.6p1 Ubuntu-4ubuntu0.3) 80/tcp nginx 443/tcp nginx |-- SSL Versions: -SSLv2, -SSLv3, -TLSv1, -TLSv1.1, -TLSv1.3, TLSv1.2 |-- Diffie-Hellman Parameters: Bits: 2048 Generator: 2 10.129.27.22 City: Berlin Country: Germany Organization: InlaneFreight Updated: 2021-09-01T15:39:55.446281 Number of open ports: 8 Ports: 25/tcp |-- SSL Versions: -SSLv2, -SSLv3, -TLSv1, -TLSv1.1, TLSv1.2, TLSv1.3 53/tcp 53/udp 80/tcp Apache httpd 81/tcp Apache httpd 110/tcp |-- SSL Versions: -SSLv2, -SSLv3, -TLSv1, -TLSv1.1, TLSv1.2 111/tcp 443/tcp Apache httpd |-- SSL Versions: -SSLv2, -SSLv3, -TLSv1, -TLSv1.1, TLSv1.2, TLSv1.3 |-- Diffie-Hellman Parameters: Bits: 2048 Generator: 2 Fingerprint: RFC3526/Oakley Group 14 444/tcp 10.129.27.33 City: Berlin Country: Germany Organization: InlaneFreight Updated: 2021-08-30T22:25:31.572717 Number of open ports: 3 Ports: 22/tcp OpenSSH (7.6p1 Ubuntu-4ubuntu0.3) 80/tcp nginx 443/tcp nginx |-- SSL Versions: -SSLv2, -SSLv3, -TLSv1, -TLSv1.1, -TLSv1.3, TLSv1.2 |-- Diffie-Hellman Parameters: Bits: 2048 Generator: 2 We remember the IP 10.129.127.22 (matomo.inlanefreight.com) for later active investigations we want to perform. Now, we can display all the available DNS records where we might find more hosts. 4.3.5 DNS Records   Domain Information notluken@htb[/htb]$ dig any inlanefreight.com ; &lt;&lt;&gt;&gt; DiG 9.16.1-Ubuntu &lt;&lt;&gt;&gt; any inlanefreight.com ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 52058 ;; flags: qr rd ra; QUERY: 1, ANSWER: 17, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 65494 ;; QUESTION SECTION: ;inlanefreight.com. IN ANY ;; ANSWER SECTION: inlanefreight.com. 300 IN A 10.129.27.33 inlanefreight.com. 300 IN A 10.129.95.250 inlanefreight.com. 3600 IN MX 1 aspmx.l.google.com. inlanefreight.com. 3600 IN MX 10 aspmx2.googlemail.com. inlanefreight.com. 3600 IN MX 10 aspmx3.googlemail.com. inlanefreight.com. 3600 IN MX 5 alt1.aspmx.l.google.com. inlanefreight.com. 3600 IN MX 5 alt2.aspmx.l.google.com. inlanefreight.com. 21600 IN NS ns.inwx.net. inlanefreight.com. 21600 IN NS ns2.inwx.net. inlanefreight.com. 21600 IN NS ns3.inwx.eu. inlanefreight.com. 3600 IN TXT &quot;MS=ms92346782372&quot; inlanefreight.com. 21600 IN TXT &quot;atlassian-domain-verification=IJdXMt1rKCy68JFszSdCKVpwPN&quot; inlanefreight.com. 3600 IN TXT &quot;google-site-verification=O7zV5-xFh_jn7JQ31&quot; inlanefreight.com. 300 IN TXT &quot;google-site-verification=bow47-er9LdgoUeah&quot; inlanefreight.com. 3600 IN TXT &quot;google-site-verification=gZsCG-BINLopf4hr2&quot; inlanefreight.com. 3600 IN TXT &quot;logmein-verification-code=87123gff5a479e-61d4325gddkbvc1-b2bnfghfsed1-3c789427sdjirew63fc&quot; inlanefreight.com. 300 IN TXT &quot;v=spf1 include:mailgun.org include:_spf.google.com include:spf.protection.outlook.com include:_spf.atlassian.net ip4:10.129.24.8 ip4:10.129.27.2 ip4:10.72.82.106 ~all&quot; inlanefreight.com. 21600 IN SOA ns.inwx.net. hostmaster.inwx.net. 2021072600 10800 3600 604800 3600 ;; Query time: 332 msec ;; SERVER: 127.0.0.53#53(127.0.0.53) ;; WHEN: Mi Sep 01 18:27:22 CEST 2021 ;; MSG SIZE rcvd: 940 Let us look at what we have learned here and come back to our principles. We see an IP record, some mail servers, some DNS servers, TXT records, and an SOA record. A records: We recognize the IP addresses that point to a specific (sub)domain through the A record. Here we only see one that we already know. MX records: The mail server records show us which mail server is responsible for managing the emails for the company. Since this is handled by google in our case, we should note this and skip it for now. NS records: These kinds of records show which name servers are used to resolve the FQDN to IP addresses. Most hosting providers use their own name servers, making it easier to identify the hosting provider. TXT records: this type of record often contains verification keys for different third-party providers and other security aspects of DNS, such as SPF, DMARC, and DKIM, which are responsible for verifying and confirming the origin of the emails sent. Here we can already see some valuable information if we look closer at the results.   Domain Information ...SNIP... TXT &quot;MS=ms92346782372&quot; ...SNIP... TXT &quot;atlassian-domain-verification=IJdXMt1rKCy68JFszSdCKVpwPN&quot; ...SNIP... TXT &quot;google-site-verification=O7zV5-xFh_jn7JQ31&quot; ...SNIP... TXT &quot;google-site-verification=bow47-er9LdgoUeah&quot; ...SNIP... TXT &quot;google-site-verification=gZsCG-BINLopf4hr2&quot; ...SNIP... TXT &quot;logmein-verification-code=87123gff5a479e-61d4325gddkbvc1-b2bnfghfsed1-3c789427sdjirew63fc&quot; ...SNIP... TXT &quot;v=spf1 include:mailgun.org include:_spf.google.com include:spf.protection.outlook.com include:_spf.atlassian.net ip4:10.129.24.8 ip4:10.129.27.2 ip4:10.72.82.106 ~all&quot; What we could see so far were entries on the DNS server, which at first glance did not look very interesting (except for the additional IP addresses). However, we could not see the third-party providers behind the entries shown at first glance. The core information we can see now is: Atlassian Google Gmail LogMeIn Mailgun Outlook INWX ID/Username 10.129.24.8 10.129.27.2 10.72.82.106 For example, Atlassian states that the company uses this solution for software development and collaboration. If we are not familiar with this platform, we can try it for free to get acquainted with it. Google Gmail indicates that Google is used for email management. Therefore, it can also suggest that we could access open GDrive folders or files with a link. LogMeIn is a central place that regulates and manages remote access on many different levels. However, the centralization of such operations is a double-edged sword. If access as an administrator to this platform is obtained (e.g., through password reuse), one also has complete access to all systems and information. Mailgun offers several email APIs, SMTP relays, and webhooks with which emails can be managed. This tells us to keep our eyes open for API interfaces that we can then test for various vulnerabilities such as IDOR, SSRF, POST, PUT requests, and many other attacks. Outlook is another indicator for document management. Companies often use Office 365 with OneDrive and cloud resources such as Azure blob and file storage. Azure file storage can be very interesting because it works with the SMB protocol. The last thing we see is INWX. This company seems to be a hosting provider where domains can be purchased and registered. The TXT record with the “MS” value is often used to confirm the domain. In most cases, it is similar to the username or ID used to log in to the management platform. 4.4 Cloud Resources The use of cloud, such as AWS, GCP, Azure, and others, is now one of the essential components for many companies nowadays. After all, all companies want to be able to do their work from anywhere, so they need a central point for all management. This is why services from Amazon (AWS), Google (GCP), and Microsoft (Azure) are ideal for this purpose. Even though cloud providers secure their infrastructure centrally, this does not mean that companies are free from vulnerabilities. The configurations made by the administrators may nevertheless make the company’s cloud resources vulnerable. This often starts with the S3 buckets (AWS), blobs (Azure), cloud storage (GCP), which can be accessed without authentication if configured incorrectly. 4.4.1 Company Hosted Servers   Cloud Resources notluken@htb[/htb]$ for i in $(cat subdomainlist);do host $i | grep &quot;has address&quot; | grep inlanefreight.com | cut -d&quot; &quot; -f1,4;done blog.inlanefreight.com 10.129.24.93 inlanefreight.com 10.129.27.33 matomo.inlanefreight.com 10.129.127.22 www.inlanefreight.com 10.129.127.33 s3-website-us-west-2.amazonaws.com 10.129.95.250 Often cloud storage is added to the DNS list when used for administrative purposes by other employees. This step makes it much easier for the employees to reach and manage them. Let us stay with the case that a company has contracted us, and during the IP lookup, we have already seen that one IP address belongs to the s3-website-us-west-2.amazonaws.com server. However, there are many different ways to find such cloud storage. One of the easiest and most used is Google search combined with Google Dorks. For example, we can use the Google Dorks inurl: and intext: to narrow our search to specific terms. In the following example, we see red censored areas containing the company name. 4.4.2 Google Search for AWS     4.4.3 Google Search for Azure     Here we can already see that the links presented by Google contain PDFs. When we search for a company that we may already know or want to know, we will also come across other files such as text documents, presentations, codes, and many others. Such content is also often included in the source code of the web pages, from where the images, JavaScript codes, or CSS are loaded. This procedure often relieves the web server and does not store unnecessary content. 4.4.4 Target Website - Source Code Third-party providers such as domain.glass can also tell us a lot about the company’s infrastructure. As a positive side effect, we can also see that Cloudflare’s security assessment status has been classified as “Safe”. This means we have already found a security measure that can be noted for the second layer (gateway). 4.4.5 Domain.Glass Results Another very useful provider is GrayHatWarfare. We can do many different searches, discover AWS, Azure, and GCP cloud storage, and even sort and filter by file format. Therefore, once we have found them through Google, we can also search for them on GrayHatWarefare and passively discover what files are stored on the given cloud storage. 4.4.6 GrayHatWarfare Results Many companies also use abbreviations of the company name, which are then used accordingly within the IT infrastructure. Such terms are also part of an excellent approach to discovering new cloud storage from the company. We can also search for files simultaneously to see the files that can be accessed at the same time. 4.4.7 Private and Public SSH Keys Leaked Sometimes when employees are overworked or under high pressure, mistakes can be fatal for the entire company. These errors can even lead to SSH private keys being leaked, which anyone can download and log onto one or even more machines in the company without using a password. 4.4.8 SSH Private Key "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
